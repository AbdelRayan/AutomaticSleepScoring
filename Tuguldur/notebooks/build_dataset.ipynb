{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets\n",
    "\n",
    "The path to dataset directory and patterns to search in those directories for the HPC, PFC recordings are loaded from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phasic_tonic.detect_phasic import detect_phasic\n",
    "from phasic_tonic.DatasetLoader import DatasetLoader\n",
    "from phasic_tonic.helper import get_metadata\n",
    "from phasic_tonic.runtime_logger import logger_setup\n",
    "from phasic_tonic.utils import get_sequences, get_segments\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynapple as nap\n",
    "import yasa\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.io import loadmat\n",
    "from mne.filter import resample\n",
    "\n",
    "fs_cbd = 2500\n",
    "fs_os = 2500\n",
    "fs_rgs = 1000\n",
    "\n",
    "targetFs = 500\n",
    "n_down_cbd = fs_cbd/targetFs\n",
    "n_down_rgs = fs_rgs/targetFs\n",
    "n_down_os = fs_os/targetFs\n",
    "\n",
    "logger = logger_setup()\n",
    "\n",
    "CONFIG_DIR = \"/home/nero/phasic_tonic/data/dataset_loading.yaml\"\n",
    "OUTPUT_DIR = \"/home/nero/datasets/preprocessed/\"\n",
    "\n",
    "Datasets = DatasetLoader(CONFIG_DIR)\n",
    "mapped_datasets = Datasets.load_datasets()\n",
    "\n",
    "def preprocess(signal: np.ndarray, n_down: int, target_fs=500) -> np.ndarray:\n",
    "    \"\"\"Downsample and remove artifacts.\"\"\"\n",
    "    \n",
    "    logger.debug(\"STARTED: Resampling to 500 Hz.\")\n",
    "    # Downsample to 500 Hz\n",
    "    data = resample(signal, down=n_down, method='fft', npad='auto')\n",
    "    logger.debug(\"FINISHED: Resampling to 500 Hz.\")\n",
    "    logger.debug(\"Resampled: {0} -> {1}.\".format(str(signal.shape), str(data.shape)))\n",
    "    \n",
    "    logger.debug(\"STARTED: Remove artifacts.\")\n",
    "    # Remove artifacts\n",
    "    art_std, _ = yasa.art_detect(data, target_fs , window=1, method='std', threshold=4)\n",
    "    art_up = yasa.hypno_upsample_to_data(art_std, 1, data, target_fs)\n",
    "    data[art_up] = 0\n",
    "    logger.debug(\"FINISHED: Remove artifacts.\")\n",
    "        \n",
    "    data -= data.mean()\n",
    "    return data\n",
    "\n",
    "def partition_to_4(rem_dict):\n",
    "    # rem_dict: dictionary with keys as tuples and values as numpy arrays\n",
    "    keys = sorted(rem_dict.keys())\n",
    "    partitions = [{} for _ in range(4)]  # Create a list of 4 empty dictionaries\n",
    "\n",
    "    for rem_idx in keys:\n",
    "        _, end = rem_idx\n",
    "        if end < 2700:  # First region\n",
    "            partitions[0][rem_idx] = rem_dict[rem_idx]\n",
    "        elif end < 5400:  # Second region\n",
    "            partitions[1][rem_idx] = rem_dict[rem_idx]\n",
    "        elif end < 8100:  # Third region\n",
    "            partitions[2][rem_idx] = rem_dict[rem_idx]\n",
    "        else:  # Fourth region\n",
    "            partitions[3][rem_idx] = rem_dict[rem_idx]\n",
    "\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of loaded recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_cnt = 0\n",
    "rgs_cnt = 0\n",
    "os_cnt = 0\n",
    "\n",
    "# Count recordings belonging to CBD dataset\n",
    "for name in mapped_datasets:\n",
    "    metadata = get_metadata(name)\n",
    "    if metadata['treatment'] == 0 or metadata['treatment'] == 1:\n",
    "        cbd_cnt += 1\n",
    "    elif metadata['treatment'] == 2 or metadata['treatment'] == 3:\n",
    "        rgs_cnt += 1\n",
    "    elif metadata['treatment'] == 4:\n",
    "        os_cnt += 1\n",
    "\n",
    "assert cbd_cnt == 170\n",
    "assert rgs_cnt == 159\n",
    "assert os_cnt == 210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dab5b2dced04afcbaeb83b1c5ace0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tqdm(mapped_datasets) as mapped_tqdm:\n",
    "    for name in mapped_tqdm:\n",
    "        metadata = get_metadata(name)\n",
    "        mapped_tqdm.set_postfix_str(name)\n",
    "        \n",
    "        logger.debug(\"Loading: {0}\".format(name))\n",
    "        states_fname, hpc_fname, pfc_fname = mapped_datasets[name]\n",
    "        logger.debug(f\"Sleep States file: {states_fname}\")\n",
    "        logger.debug(f\"HPC file: {hpc_fname}\")\n",
    "        logger.debug(f\"PFC file: {pfc_fname}\")\n",
    "        \n",
    "\n",
    "        if metadata[\"treatment\"] == 0 or metadata[\"treatment\"] == 1:\n",
    "            n_down = n_down_cbd\n",
    "        elif metadata[\"treatment\"] == 2 or metadata[\"treatment\"] == 3:\n",
    "            n_down = n_down_rgs\n",
    "        elif metadata[\"treatment\"] == 4:\n",
    "            n_down = n_down_os\n",
    "        \n",
    "        # Load the LFP data\n",
    "        lfpHPC = loadmat(hpc_fname)['HPC'].flatten()\n",
    "\n",
    "        # Load the states\n",
    "        hypno = loadmat(states_fname)['states'].flatten()\n",
    "    \n",
    "        logger.debug(\"STARTED: Extract REM epochs.\")    \n",
    "        # Skip if no REM epoch is detected\n",
    "        if(not (np.any(hypno == 5))):\n",
    "            logger.debug(\"No REM detected. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        rem_idx = []\n",
    "        min_duration = 3\n",
    "        for start, end in get_sequences(np.where(hypno == 5)[0]):\n",
    "            if (end-start) > min_duration:\n",
    "                rem_idx.append((start, end))\n",
    "\n",
    "        if len(rem_idx) == 0:\n",
    "            logger.debug(\"No REM epochs greater than min_dur.\")\n",
    "            logger.debug(f\"{rem_idx}\")\n",
    "            continue\n",
    "\n",
    "        rem_seq = [(start*targetFs, (end+1)*targetFs) for start, end in rem_idx]\n",
    "        logger.debug(\"FINISHED: Extract REM epochs.\")\n",
    "        logger.debug(f\"REM Epochs: {rem_seq}\")\n",
    "\n",
    "        lfpHPC_down = preprocess(lfpHPC, n_down)\n",
    "        rem_seg = get_segments(rem_seq, lfpHPC_down)\n",
    "\n",
    "        rem = {idx:array for idx, array in zip(rem_idx, rem_seg)}\n",
    "        del rem_seg, rem_seq\n",
    "        \n",
    "        if metadata[\"trial_num\"] == '5':\n",
    "            for i, partition in enumerate(partition_to_4(rem)):\n",
    "                metadata[\"trial_num\"] = '5-' + str(i+1)\n",
    "                logger.debug(\"Partition: {0}\".format(str(partition.keys())))\n",
    "                \n",
    "                fname = f\"{name}-{i}.npz\"\n",
    "                logger.debug(f\"Saving to {fname}.\")\n",
    "                \n",
    "                # Convert keywords to strings to save as npz\n",
    "                np.savez(OUTPUT_DIR+fname, **{str(key): value for key, value in partition.items()})\n",
    "        else:\n",
    "            fname = f\"{name}.npz\"\n",
    "            logger.debug(f\"Saving to {fname}.\")\n",
    "            \n",
    "            # Convert keywords to strings to save as npz\n",
    "            np.savez(OUTPUT_DIR+fname, **{str(key): value for key, value in rem.items()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
