{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phasic_tonic.detect_phasic import detect_phasic_v2\n",
    "from phasic_tonic.helper import get_metadata\n",
    "from phasic_tonic.runtime_logger import logger_setup\n",
    "from phasic_tonic.utils import get_sequences, get_segments\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynapple as nap\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "fs = 500\n",
    "\n",
    "logger = logger_setup()\n",
    "\n",
    "CONFIG_DIR = \"/home/nero/phasic_tonic/data/dataset_loading.yaml\"\n",
    "DATASET_DIR = \"/home/nero/datasets/preprocessed\"\n",
    "OUTPUT_DIR1 = \"/home/nero/phasic_tonic/data/analysis_output/whole_posttrial5/\"\n",
    "OUTPUT_DIR2 = \"/home/nero/phasic_tonic/data/analysis_output/segmented_posttrial5/\"\n",
    "\n",
    "def str_to_tuple(string):\n",
    "    string = string.strip(\"()\")\n",
    "    parts = string.split(\",\")\n",
    "    return tuple(map(int, parts))\n",
    "\n",
    "def load_data(fname):\n",
    "    loaded_data = np.load(fname)\n",
    "    loaded_dict = {str_to_tuple(key): loaded_data[key] for key in loaded_data.files}\n",
    "    return loaded_dict\n",
    "\n",
    "compressed_datasets = list(Path(DATASET_DIR).glob('*.npz'))\n",
    "len(compressed_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emd\n",
    "from neurodsp.filt import filter_signal\n",
    "\n",
    "def compute_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "def asc2desc(x):\n",
    "    \"\"\"Ascending to Descending ratio ( A / A+D ).\"\"\"\n",
    "    pt = emd.cycles.cf_peak_sample(x, interp=True)\n",
    "    tt = emd.cycles.cf_trough_sample(x, interp=True)\n",
    "    if (pt is None) or (tt is None):\n",
    "        return np.nan\n",
    "    asc = pt + (len(x) - tt)\n",
    "    #desc = tt - pt\n",
    "    return asc / len(x)\n",
    "\n",
    "def peak2trough(x):\n",
    "    \"\"\"Peak to trough ratio ( P / P+T ).\"\"\"\n",
    "    des = emd.cycles.cf_descending_zero_sample(x, interp=True)\n",
    "    if des is None:\n",
    "        return np.nan\n",
    "    return des / len(x)\n",
    "\n",
    "def compute_cycles(signal, fs, metadata):\n",
    "    signal = filter_signal(signal, fs, 'bandpass', (5,12), remove_edges=False)\n",
    "    # Perform EMD and compute cycle metrics\n",
    "    IP, IF, IA = emd.spectra.frequency_transform(signal, fs, 'hilbert', smooth_phase=3)\n",
    "    C = emd.cycles.Cycles(IP.flatten())\n",
    "    # print(\"Detected cycles before extraction:\")\n",
    "    # print(C)\n",
    "\n",
    "    # Compute cycle metrics\n",
    "    C.compute_cycle_metric('start_sample', np.arange(len(C.cycle_vect)), emd.cycles.cf_start_value)\n",
    "    C.compute_cycle_metric('stop_sample', signal, emd.cycles.cf_end_value)\n",
    "    C.compute_cycle_metric('peak_sample', signal, emd.cycles.cf_peak_sample)\n",
    "    C.compute_cycle_metric('desc_sample', signal, emd.cycles.cf_descending_zero_sample)\n",
    "    C.compute_cycle_metric('trough_sample', signal, emd.cycles.cf_trough_sample)\n",
    "    C.compute_cycle_metric('duration_samples', signal, len)\n",
    "    C.compute_cycle_metric('max_amp', IA, np.max)\n",
    "    C.compute_cycle_metric('mean_if', IF, np.mean)\n",
    "    C.compute_cycle_metric('max_if', IF, np.max)\n",
    "    C.compute_cycle_metric('range_if', IF, compute_range)  # Make sure 'compute_range' is defined\n",
    "    C.compute_cycle_metric('asc2desc', signal, asc2desc)  # Make sure 'asc2desc' is defined\n",
    "    C.compute_cycle_metric('peak2trough', signal, peak2trough)  # Make sure 'peak2trough' is defined\n",
    "\n",
    "    # print('\\nFinished computing the cycles metrics\\n')\n",
    "\n",
    "    # Extract a subset of the cycles\n",
    "    amp_thresh = np.percentile(IA, 25)\n",
    "    lo_freq_duration = fs / 5\n",
    "    hi_freq_duration = fs / 12\n",
    "    conditions = ['is_good==1',\n",
    "                  f'duration_samples<{lo_freq_duration}',\n",
    "                  f'duration_samples>{hi_freq_duration}',\n",
    "                  f'max_amp>{amp_thresh}']\n",
    "\n",
    "    # print(\"Cycles after extraction:\")\n",
    "    df_emd = C.get_metric_dataframe(conditions=conditions)\n",
    "    # print(f'{len(df_emd)}')\n",
    "\n",
    "    #Add the metadata\n",
    "    df_emd[\"rat\"]       = metadata[\"rat_id\"]\n",
    "    df_emd[\"study_day\"] = metadata[\"study_day\"]\n",
    "    df_emd[\"condition\"] = metadata[\"condition\"]\n",
    "    df_emd[\"treatment\"] = metadata[\"treatment\"]\n",
    "    df_emd[\"trial_num\"] = metadata[\"trial_num\"]\n",
    "    df_emd[\"state\"]     = metadata[\"state\"]\n",
    "    \n",
    "    start, end = metadata[\"interval\"]\n",
    "    df_emd[\"start\"] = start\n",
    "    df_emd[\"end\"] = end\n",
    "\n",
    "    return df_emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapped_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m combined \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\u001b[43mmapped_datasets\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m mapped_tqdm:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m mapped_tqdm:\n\u001b[1;32m      5\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m get_metadata(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mapped_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "combined = []\n",
    "\n",
    "with tqdm(mapped_datasets) as mapped_tqdm:\n",
    "    for name in mapped_tqdm:\n",
    "        metadata = get_metadata(name)\n",
    "        mapped_tqdm.set_postfix_str(name)\n",
    "        states_fname, hpc_fname, pfc_fname = mapped_datasets[name]\n",
    "        logger.debug(\"Loading: {0}\".format(name))\n",
    "\n",
    "        if metadata[\"treatment\"] == 0 or metadata[\"treatment\"] == 1:\n",
    "            n_down = n_down_cbd\n",
    "        elif metadata[\"treatment\"] == 2 or metadata[\"treatment\"] == 3:\n",
    "            n_down = n_down_rgs\n",
    "        elif metadata[\"treatment\"] == 4:\n",
    "            n_down = n_down_os\n",
    "        \n",
    "        # Load the LFP data\n",
    "        lfpHPC = loadmat(hpc_fname)['HPC'].flatten()\n",
    "\n",
    "        # Load the states\n",
    "        hypno = loadmat(states_fname)['states'].flatten()\n",
    "        \n",
    "        # Skip if no REM epoch is detected\n",
    "        if(not (np.any(hypno == 5))):\n",
    "            logger.debug(\"No REM detected. Skipping.\")\n",
    "            continue\n",
    "        elif(np.sum(np.diff(get_sequences(np.where(hypno == 5)[0]))) < 10):\n",
    "            logger.debug(\"No REM longer than 10s. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Detect phasic intervals\n",
    "        lfpHPC_down = preprocess(lfpHPC, n_down)\n",
    "        phrem = detect_phasic(lfpHPC_down, hypno, targetFs)\n",
    "        break\n",
    "        t = np.arange(0, len(lfpHPC_down)/targetFs, 1/targetFs)\n",
    "        lfp = nap.Tsd(t=t, d=lfpHPC_down)\n",
    "        \n",
    "        start, end = [], []\n",
    "        rem_start, rem_end = [], []\n",
    "        for rem_idx in phrem:\n",
    "            rem_start.append(rem_idx[0])\n",
    "            rem_end.append(rem_idx[1])\n",
    "\n",
    "            for s, e in phrem[rem_idx]:\n",
    "                start.append(s / targetFs)\n",
    "                end.append(e / targetFs)\n",
    "        \n",
    "        rem_interval = nap.IntervalSet(rem_start, rem_end)\n",
    "        phasic_interval = nap.IntervalSet(start, end)\n",
    "        tonic_interval = rem_interval.set_diff(phasic_interval)\n",
    "\n",
    "        phasic_interval = phasic_interval.drop_short_intervals(0.6)\n",
    "        tonic_interval = tonic_interval.drop_short_intervals(0.6)\n",
    "        \n",
    "        #Compute waveform dynamics for each intervals\n",
    "        metadata['state'] = 'phasic'\n",
    "        for i in range(len(phasic_interval)):\n",
    "            metadata['interval'] = (phasic_interval[i]['start'].item(), phasic_interval[i]['end'].item())\n",
    "            df_emd = compute_cycles(lfp.restrict(phasic_interval[i]).to_numpy(), lfp.rate, metadata)\n",
    "            combined.append(df_emd)\n",
    "            \n",
    "        metadata['state'] = 'tonic'\n",
    "        for i in range(len(tonic_interval)):\n",
    "            metadata['interval'] = (tonic_interval[i]['start'].item(), tonic_interval[i]['end'].item())\n",
    "            df_emd = compute_cycles(lfp.restrict(tonic_interval[i]).to_numpy(), lfp.rate, metadata)\n",
    "            combined.append(df_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddbc92a438946b3b59556f04e176cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = []\n",
    "\n",
    "with tqdm(compressed_datasets) as datasets:\n",
    "    for fname in datasets:\n",
    "        metaname = str(fname.stem)\n",
    "\n",
    "        datasets.set_postfix_str(metaname)\n",
    "        metadata = get_metadata(metaname)\n",
    "\n",
    "        rem_epochs = load_data(fname)\n",
    "\n",
    "        if not rem_epochs:\n",
    "            continue\n",
    "        \n",
    "        phrem = detect_phasic_v2(rem_epochs, fs)\n",
    "        \n",
    "        start, end = [], []\n",
    "        rem_start, rem_end = [], []\n",
    "        for rem_idx in phrem:\n",
    "            rem_start.append(rem_idx[0])\n",
    "            rem_end.append(rem_idx[1])\n",
    "\n",
    "            for s, e in phrem[rem_idx]:\n",
    "                start.append(s / fs)\n",
    "                end.append(e / fs)\n",
    "        \n",
    "        rem_interval = nap.IntervalSet(rem_start, rem_end)\n",
    "        phasic_interval = nap.IntervalSet(start, end)\n",
    "        tonic_interval = rem_interval.set_diff(phasic_interval)\n",
    "\n",
    "        break\n",
    "        t = np.arange(0, len(lfpHPC_down)/targetFs, 1/targetFs)\n",
    "        lfp = nap.Tsd(t=t, d=lfpHPC_down)\n",
    "        \n",
    "        start, end = [], []\n",
    "        rem_start, rem_end = [], []\n",
    "        for rem_idx in phrem:\n",
    "            rem_start.append(rem_idx[0])\n",
    "            rem_end.append(rem_idx[1])\n",
    "\n",
    "            for s, e in phrem[rem_idx]:\n",
    "                start.append(s / targetFs)\n",
    "                end.append(e / targetFs)\n",
    "        \n",
    "        rem_interval = nap.IntervalSet(rem_start, rem_end)\n",
    "        phasic_interval = nap.IntervalSet(start, end)\n",
    "        tonic_interval = rem_interval.set_diff(phasic_interval)\n",
    "\n",
    "        phasic_interval = phasic_interval.drop_short_intervals(0.6)\n",
    "        tonic_interval = tonic_interval.drop_short_intervals(0.6)\n",
    "        \n",
    "        #Compute waveform dynamics for each intervals\n",
    "        metadata['state'] = 'phasic'\n",
    "        for i in range(len(phasic_interval)):\n",
    "            metadata['interval'] = (phasic_interval[i]['start'].item(), phasic_interval[i]['end'].item())\n",
    "            df_emd = compute_cycles(lfp.restrict(phasic_interval[i]).to_numpy(), lfp.rate, metadata)\n",
    "            combined.append(df_emd)\n",
    "            \n",
    "        metadata['state'] = 'tonic'\n",
    "        for i in range(len(tonic_interval)):\n",
    "            metadata['interval'] = (tonic_interval[i]['start'].item(), tonic_interval[i]['end'].item())\n",
    "            df_emd = compute_cycles(lfp.restrict(tonic_interval[i]).to_numpy(), lfp.rate, metadata)\n",
    "            combined.append(df_emd)\n",
    "\n",
    "        if metadata['trial_num'] in ['5-0', '5-1', '5-2', '5-3']:\n",
    "            a, b = metadata['trial_num'].split('-')\n",
    "            metadata['trial_num'] = a + '.' + str(int(b)+1)\n",
    "        \n",
    "        # Save duration bouts\n",
    "        for state, interval in [(\"phasic\", phasic_interval), (\"tonic\", tonic_interval)]:\n",
    "            for condition in metadata.keys():\n",
    "                per_trial_stats[condition].append(metadata[condition])\n",
    "            per_trial_stats['state'].append(state)\n",
    "            per_trial_stats['total_duration'].append(interval.tot_length())\n",
    "            per_trial_stats['num_bouts'].append(len(interval))\n",
    "\n",
    "# df_trial = pd.DataFrame(per_trial_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(9121,\n",
       "  9168): array([-521.40680664, -425.96849279, -371.52721119, ...,  -47.62286642,\n",
       "         -41.44032593,  -24.79185434]),\n",
       " (9430,\n",
       "  9468): array([-352.73359408, -372.59991162, -369.94954227, ..., -238.26998387,\n",
       "        -208.68342674, -167.58037353]),\n",
       " (9738,\n",
       "  9820): array([-111.45551596, -177.1756736 , -245.16593697, ...,   18.80917785,\n",
       "         -23.71035767,  -96.97847569])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = []\n",
    "\n",
    "with tqdm(compressed_datasets) as datasets:\n",
    "    for fname in datasets:\n",
    "        metaname = str(fname.stem)\n",
    "\n",
    "        datasets.set_postfix_str(metaname)\n",
    "        metadata = get_metadata(metaname)\n",
    "\n",
    "        rem_epochs = load_data(fname)\n",
    "\n",
    "        if not rem_epochs:\n",
    "            continue\n",
    "        \n",
    "        phrem = detect_phasic_v2(rem_epochs, fs)\n",
    "\n",
    "        for rem_idx in rem_epochs:\n",
    "            lfpREM = rem_epochs[rem_idx]\n",
    "            phasic_intervals = phrem[rem_idx]\n",
    "            phasic, tonic = [], []\n",
    "            if phasic_intervals:\n",
    "                for start, end in phasic_intervals:\n",
    "                    phasic.append(lfp[start:end])\n",
    "            else:\n",
    "                tonic.append(lfp)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            start      end\n",
       "       0  9158     9158.99\n",
       "       1  9788.73  9790.73\n",
       "       2  9808.62  9810.67\n",
       "       3  9811.39  9812.98\n",
       "shape: (4, 2), time unit: sec."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nap.IntervalSet(start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             start    end\n",
      "       0     9121   9168\n",
      "shape: (1, 2), time unit: sec.\n",
      "1             start    end\n",
      "       0     9430   9468\n",
      "shape: (1, 2), time unit: sec.\n",
      "2             start    end\n",
      "       0     9738   9820\n",
      "shape: (1, 2), time unit: sec.\n"
     ]
    }
   ],
   "source": [
    "for i, interval in enumerate(rem_interval):\n",
    "    print(i, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9158.99"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4579495/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            start    end\n",
       "       0     9121   9168\n",
       "       1     9430   9468\n",
       "       2     9738   9820\n",
       "shape: (3, 2), time unit: sec."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rem_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            start      end\n",
       "       0  9121     9158\n",
       "       1  9158.99  9168\n",
       "       2  9430     9468\n",
       "       3  9738     9788.73\n",
       "       4  9790.73  9808.62\n",
       "       5  9810.67  9811.39\n",
       "       6  9812.98  9820\n",
       "shape: (7, 2), time unit: sec."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tonic_interval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phasic_tonic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
