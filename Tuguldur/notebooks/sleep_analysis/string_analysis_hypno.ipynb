{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phasic_tonic.detect_phasic import detect_phasic, detect_phasic_v2\n",
    "from phasic_tonic.DatasetLoader import DatasetLoader\n",
    "from phasic_tonic.helper import get_metadata\n",
    "from phasic_tonic.runtime_logger import logger_setup\n",
    "from phasic_tonic.utils import get_sequences, load_data, preprocess\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "fs_cbd = 2500\n",
    "fs_os = 2500\n",
    "fs_rgs = 1000\n",
    "\n",
    "targetFs = 500\n",
    "n_down_cbd = fs_cbd/targetFs\n",
    "n_down_rgs = fs_rgs/targetFs\n",
    "n_down_os = fs_os/targetFs\n",
    "\n",
    "logger = logger_setup()\n",
    "\n",
    "CONFIG_DIR = \"/home/nero/phasic_tonic/data/dataset_loading.yaml\"\n",
    "DATASET_DIR = \"/home/nero/datasets/preprocessed\"\n",
    "OUTPUT_DIR1 = \"/home/nero/phasic_tonic/data/analysis_output/whole_posttrial5/\"\n",
    "OUTPUT_DIR2 = \"/home/nero/phasic_tonic/data/analysis_output/segmented_posttrial5/\"\n",
    "\n",
    "def half_round_up(n):\n",
    "    if n - math.floor(n) < 0.5:\n",
    "        return math.floor(n)\n",
    "    else:\n",
    "        return math.ceil(n)\n",
    "\n",
    "compressed_datasets = list(Path(DATASET_DIR).glob('*.npz'))\n",
    "\n",
    "Datasets = DatasetLoader(CONFIG_DIR)\n",
    "mapped_datasets = Datasets.load_datasets()\n",
    "\n",
    "len(compressed_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_dict = {\n",
    "    1:\"W\",\n",
    "    3:\"N\",\n",
    "    4:\"I\",\n",
    "    5:\"R\"\n",
    "    }\n",
    "\n",
    "phasic_tonic_dict = {\n",
    "    1:\"W\",\n",
    "    3:\"N\",\n",
    "    4:\"I\",\n",
    "    6:\"T\",\n",
    "    7:\"P\"\n",
    "}\n",
    "\n",
    "def array_to_string(array, mapping_dict):\n",
    "    for e in np.unique(array):\n",
    "        if e not in mapping_dict:\n",
    "            mapping_dict[e] = \"_\"\n",
    "    result = \"\"\n",
    "    for x in array:\n",
    "        result += mapping_dict[x]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole post-trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000764607e9443fca9792bda0df99bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "container = []\n",
    "\n",
    "with tqdm(mapped_datasets) as mapped_tqdm:\n",
    "    for name in mapped_tqdm:\n",
    "        metadata = get_metadata(name)\n",
    "        mapped_tqdm.set_postfix_str(name)\n",
    "        states_fname, hpc_fname, _ = mapped_datasets[name]\n",
    "        logger.debug(\"Loading: {0}\".format(name))\n",
    "\n",
    "        if metadata[\"treatment\"] == 0 or metadata[\"treatment\"] == 1:\n",
    "            n_down = n_down_cbd\n",
    "        elif metadata[\"treatment\"] == 2 or metadata[\"treatment\"] == 3:\n",
    "            n_down = n_down_rgs\n",
    "        elif metadata[\"treatment\"] == 4:\n",
    "            n_down = n_down_os\n",
    "        \n",
    "        # Load the LFP data\n",
    "        lfpHPC = loadmat(hpc_fname)['HPC'].flatten()\n",
    "        # Load the sleep states\n",
    "        hypno = loadmat(states_fname)['states'].flatten()\n",
    "\n",
    "        metadata[\"string_rem\"] = array_to_string(np.nan_to_num(hypno), sleep_dict)\n",
    "        metadata[\"string_phasic_tonic\"] = \"\"\n",
    "\n",
    "        # Skip if no REM epoch is detected\n",
    "        if(not (np.any(hypno == 5))):\n",
    "            logger.debug(\"No REM detected. Skipping.\")\n",
    "            continue\n",
    "        elif(np.sum(np.diff(get_sequences(np.where(hypno == 5)[0]))) < 10):\n",
    "            logger.debug(\"No REM longer than 10s. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Detect phasic intervals\n",
    "        lfpHPC_down = preprocess(lfpHPC, n_down)\n",
    "        phREM = detect_phasic(lfpHPC_down, hypno, targetFs)\n",
    "\n",
    "        # Classify each REM time window as tonic or phasic event\n",
    "        for rem_idx in phREM:\n",
    "            rem_start, rem_end = rem_idx[0], rem_idx[1]\n",
    "            phasic_idx = phREM[rem_idx]\n",
    "            \n",
    "            # Initialize the REM epoch as tonic states (6)\n",
    "            hypno[rem_start:(rem_end+1)] = 6\n",
    "\n",
    "            if phasic_idx:\n",
    "                for s, e in phasic_idx:\n",
    "                    # Round up the phasic timestamp if its fractional part is greater than 0.5\n",
    "                    ph_start, ph_end = half_round_up(s/targetFs), half_round_up(e/targetFs)\n",
    "                    \n",
    "                    # Fill the phasic states as 1\n",
    "                    hypno[ph_start:ph_end] = 7\n",
    "            \n",
    "        metadata[\"string_phasic_tonic\"] = array_to_string(np.nan_to_num(hypno), phasic_tonic_dict)\n",
    "        container.append(metadata)\n",
    "\n",
    "df = pd.DataFrame(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"string_analysis_hypno.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmented post-trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_string(s, part_size=2700):\n",
    "    parts = [s[i*part_size:(i+1)*part_size] for i in range(4)]\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rat_id</th>\n",
       "      <th>study_day</th>\n",
       "      <th>condition</th>\n",
       "      <th>treatment</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>string_rem</th>\n",
       "      <th>string_phasic_tonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>HC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>HC</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNNNNNNNNNNNNNNNN...</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNNNNNNNNNNNNNNNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>HC</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>HC</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
       "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>OR</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rat_id  study_day condition  treatment trial_num  \\\n",
       "0       5          8        HC          0         3   \n",
       "1       5          8        HC          0         2   \n",
       "2       5          8        HC          0         4   \n",
       "3       5          8        HC          0         5   \n",
       "4       5         16        OR          1         5   \n",
       "\n",
       "                                          string_rem  \\\n",
       "0  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...   \n",
       "1  WWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNNNNNNNNNNNNNNNN...   \n",
       "2  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...   \n",
       "3  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...   \n",
       "4  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...   \n",
       "\n",
       "                                 string_phasic_tonic  \n",
       "0  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...  \n",
       "1  WWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNNNNNNNNNNNNNNNN...  \n",
       "2  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...  \n",
       "3  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...  \n",
       "4  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seg = df.copy()\n",
    "df_seg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10914\n",
      "10938\n",
      "9481\n",
      "10801\n",
      "10800\n",
      "10807\n",
      "10800\n",
      "10800\n",
      "10800\n",
      "10800\n",
      "10800\n",
      "10800\n",
      "10804\n",
      "10803\n",
      "10801\n",
      "10800\n",
      "10801\n",
      "10802\n",
      "10802\n",
      "10800\n",
      "10801\n",
      "10820\n",
      "10799\n",
      "10800\n",
      "10801\n",
      "10800\n",
      "10815\n",
      "10800\n",
      "10801\n",
      "10800\n",
      "10800\n",
      "10800\n",
      "10801\n",
      "10799\n",
      "10800\n",
      "10800\n",
      "10825\n",
      "10799\n",
      "10818\n",
      "10789\n",
      "10800\n",
      "10796\n",
      "10801\n",
      "10805\n",
      "9459\n",
      "10797\n",
      "10547\n",
      "10800\n",
      "10800\n",
      "10799\n",
      "10080\n",
      "10799\n",
      "10799\n",
      "10800\n",
      "10012\n",
      "10800\n",
      "10815\n",
      "10799\n",
      "10800\n",
      "10800\n",
      "10799\n",
      "10758\n",
      "10800\n",
      "10471\n",
      "10813\n",
      "10827\n",
      "10749\n",
      "10168\n",
      "10284\n",
      "10195\n",
      "10419\n",
      "10799\n",
      "10801\n",
      "10799\n",
      "10217\n",
      "10838\n",
      "10804\n",
      "10805\n",
      "10800\n",
      "10800\n",
      "10800\n",
      "10762\n",
      "10781\n",
      "9617\n",
      "10800\n",
      "10834\n",
      "10830\n",
      "10913\n",
      "10542\n",
      "10928\n",
      "10807\n",
      "10243\n",
      "10802\n",
      "10914\n",
      "10817\n",
      "10806\n",
      "10813\n",
      "10812\n",
      "10739\n",
      "10800\n",
      "10800\n",
      "10349\n",
      "10832\n"
     ]
    }
   ],
   "source": [
    "new_df = []\n",
    "for i, row in df_seg.iterrows():\n",
    "    if row['trial_num'] == '5':\n",
    "        #print(len(row['string_rem']))\n",
    "        parts_rem = partition_string(row['string_rem'])\n",
    "        parts_phrem = partition_string(row['string_phasic_tonic'])\n",
    "        for j, string_rem in enumerate(parts_rem):\n",
    "            row['trial_num'] = '5.' + str(j+1)\n",
    "            row['string_rem'] = string_rem\n",
    "            row['string_phasic_tonic'] = parts_phrem[j]\n",
    "            new_df.append(pd.DataFrame([row]))\n",
    "    else:\n",
    "        new_df.append(pd.DataFrame([row]))\n",
    "# df2 = pd.concat(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2=pd.concat(new_df, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2.to_csv('string_analysis_hypno.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg = pd.read_csv(\"/home/nero/phasic_tonic/data/analysis_output/segmented_posttrial5/string_analysis_hypno.csv\", index_col=0)\n",
    "df_whole = pd.read_csv(\"/home/nero/phasic_tonic/data/analysis_output/whole_posttrial5/string_analysis_hypno.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latency(string):\n",
    "    latencies = {}\n",
    "    if (\"P\" in string) or (\"T\" in string):\n",
    "        for state in [\"W\", \"N\", \"I\", \"P\", \"T\"]:\n",
    "            latencies[state] = string.find(state)\n",
    "    else:\n",
    "        for state in [\"W\", \"N\", \"I\", \"R\"]:\n",
    "            latencies[state] = string.find(state)\n",
    "    return latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = []\n",
    "for i, row in df_seg.iterrows():\n",
    "    latencies = compute_latency(row['string_rem'])\n",
    "    for state in latencies:\n",
    "        row[state] = latencies[state]\n",
    "    row['P'] = row['string_phasic_tonic'].find(\"P\")\n",
    "    row['T'] = row['string_phasic_tonic'].find(\"T\")\n",
    "    container.append(row)\n",
    "lat_df = pd.DataFrame(container)\n",
    "lat_df.to_csv(\"string_analysis_latency.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = []\n",
    "for i, row in df_whole.iterrows():\n",
    "    latencies = compute_latency(row['string_rem'])\n",
    "    for state in latencies:\n",
    "        row[state] = latencies[state]\n",
    "    row['P'] = row['string_phasic_tonic'].find(\"P\")\n",
    "    row['T'] = row['string_phasic_tonic'].find(\"T\")\n",
    "    container.append(row)\n",
    "lat_df = pd.DataFrame(container)\n",
    "lat_df.to_csv(\"string_analysis_latency.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phasic_tonic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
