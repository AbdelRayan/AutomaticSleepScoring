{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nero/AutomaticSleepScoring/Tuguldur') # change this to your local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.detect_phasic import detect_phasic, detect_phasic_v2\n",
    "from pipeline.DatasetLoader import DatasetLoader\n",
    "from pipeline.helper import get_metadata\n",
    "from pipeline.runtime_logger import logger_setup\n",
    "from pipeline.utils import get_sequences, preprocess\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "fs_cbd = 2500\n",
    "fs_os = 2500\n",
    "fs_rgs = 1000\n",
    "\n",
    "targetFs = 500\n",
    "n_down_cbd = fs_cbd/targetFs\n",
    "n_down_rgs = fs_rgs/targetFs\n",
    "n_down_os = fs_os/targetFs\n",
    "\n",
    "logger = logger_setup()\n",
    "\n",
    "CONFIG_DIR = \"/home/nero/AutomaticSleepScoring/Tuguldur/data/dataset_loading.yaml\"\n",
    "DATASET_DIR = \"/home/nero/datasets/preprocessed\"\n",
    "OUTPUT_DIR1 = \"/home/nero/AutomaticSleepScoring/Tuguldur/data/analysis_output/whole_posttrial5/\"\n",
    "OUTPUT_DIR2 = \"/home/nero/AutomaticSleepScoring/Tuguldur/data/analysis_output/segmented_posttrial5/\"\n",
    "\n",
    "def half_round_up(n):\n",
    "    if n - math.floor(n) < 0.5:\n",
    "        return math.floor(n)\n",
    "    else:\n",
    "        return math.ceil(n)\n",
    "\n",
    "compressed_datasets = list(Path(DATASET_DIR).glob('*.npz'))\n",
    "\n",
    "Datasets = DatasetLoader(CONFIG_DIR)\n",
    "mapped_datasets = Datasets.load_datasets()\n",
    "\n",
    "len(compressed_datasets)\n",
    "\n",
    "def str_to_tuple(string):\n",
    "    string = string.strip(\"()\")\n",
    "    parts = string.split(\",\")\n",
    "    return tuple(map(int, parts))\n",
    "\n",
    "def load_data(fname):\n",
    "    loaded_data = np.load(fname)\n",
    "    loaded_dict = {str_to_tuple(key): loaded_data[key] for key in loaded_data.files}\n",
    "    return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1194, 1435) : 241 ----> 242\n",
      "(2460, 2528) : 68 ----> 69\n",
      "(2552, 2631) : 79 ----> 80\n",
      "(2676, 2756) : 80 ----> 81\n",
      "(3266, 3313) : 47 ----> 48\n",
      "(4168, 4454) : 286 ----> 287\n",
      "(5090, 5125) : 35 ----> 36\n",
      "(5886, 6053) : 167 ----> 168\n",
      "(7379, 7428) : 49 ----> 50\n",
      "(7850, 7866) : 16 ----> 17\n",
      "(8002, 8034) : 32 ----> 33\n",
      "(8628, 8732) : 104 ----> 105\n",
      "(10204, 10485) : 281 ----> 282\n"
     ]
    }
   ],
   "source": [
    "from pipeline.utils import get_rem_epochs\n",
    "states_fname, hpc_fname, _ = mapped_datasets['Rat1_SD1_OD_4_posttrial5']\n",
    "\n",
    "# Load the LFP data\n",
    "lfpHPC = loadmat(hpc_fname)['HPC'].flatten()\n",
    "# Load the states\n",
    "hypno = loadmat(states_fname)['states'].flatten()\n",
    "\n",
    "rem_epochs = get_rem_epochs(lfpHPC, hypno, fs=2500)\n",
    "for rem_idx in rem_epochs:\n",
    "    print(f\"{rem_idx[0], rem_idx[1]} : {rem_idx[1]-rem_idx[0]} ----> {rem_epochs[rem_idx].shape[0]//2500}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_dict = {\n",
    "    1:\"W\",\n",
    "    3:\"N\",\n",
    "    4:\"I\",\n",
    "    5:\"R\"\n",
    "    }\n",
    "\n",
    "phasic_tonic_dict = {\n",
    "    1:\"W\",\n",
    "    3:\"N\",\n",
    "    4:\"I\",\n",
    "    6:\"T\",\n",
    "    7:\"P\"\n",
    "}\n",
    "\n",
    "def array_to_string(array, mapping_dict):\n",
    "    for e in np.unique(array):\n",
    "        if e not in mapping_dict:\n",
    "            mapping_dict[e] = \"_\"\n",
    "    result = \"\"\n",
    "    for x in array:\n",
    "        result += mapping_dict[x]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole post-trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c5d6c7da6143a1a0e48893b47d5d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "container = []\n",
    "\n",
    "with tqdm(mapped_datasets) as mapped_tqdm:\n",
    "    for name in mapped_tqdm:\n",
    "        metadata = get_metadata(name)\n",
    "        mapped_tqdm.set_postfix_str(name)\n",
    "        states_fname, hpc_fname, _ = mapped_datasets[name]\n",
    "        logger.debug(\"Loading: {0}\".format(name))\n",
    "\n",
    "        if metadata[\"treatment\"] == 0 or metadata[\"treatment\"] == 1:\n",
    "            n_down = n_down_cbd\n",
    "        elif metadata[\"treatment\"] == 2 or metadata[\"treatment\"] == 3:\n",
    "            n_down = n_down_rgs\n",
    "        elif metadata[\"treatment\"] == 4:\n",
    "            n_down = n_down_os\n",
    "        \n",
    "        # Load the LFP data\n",
    "        lfpHPC = loadmat(hpc_fname)['HPC'].flatten()\n",
    "        # Load the sleep states\n",
    "        hypno = loadmat(states_fname)['states'].flatten()\n",
    "\n",
    "        metadata[\"string_rem\"] = array_to_string(np.nan_to_num(hypno), sleep_dict)\n",
    "        metadata[\"string_phasic_tonic\"] = \"\"\n",
    "\n",
    "        # Skip if no REM epoch is detected\n",
    "        if(not (np.any(hypno == 5))):\n",
    "            logger.debug(\"No REM detected. Skipping.\")\n",
    "            continue\n",
    "        elif(np.sum(np.diff(get_sequences(np.where(hypno == 5)[0]))) < 10):\n",
    "            logger.debug(\"No REM longer than 10s. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Detect phasic intervals\n",
    "        lfpHPC_down = preprocess(lfpHPC, n_down)\n",
    "        phREM = detect_phasic(lfpHPC_down, hypno, targetFs)\n",
    "\n",
    "        # Classify each REM time window as tonic or phasic event\n",
    "        for rem_idx in phREM:\n",
    "            rem_start, rem_end = rem_idx[0], rem_idx[1]\n",
    "            phasic_idx = phREM[rem_idx]\n",
    "            \n",
    "            # Initialize the REM epoch as tonic states (6)\n",
    "            hypno[rem_start:(rem_end+1)] = 6\n",
    "\n",
    "            if phasic_idx:\n",
    "                for s, e in phasic_idx:\n",
    "                    # Round up the phasic timestamp if its fractional part is greater than 0.5\n",
    "                    ph_start, ph_end = half_round_up(s/targetFs), half_round_up(e/targetFs)\n",
    "                    \n",
    "                    # Fill the phasic states as 1\n",
    "                    hypno[ph_start:ph_end] = 7\n",
    "            \n",
    "        metadata[\"string_phasic_tonic\"] = array_to_string(np.nan_to_num(hypno), phasic_tonic_dict)\n",
    "        container.append(metadata)\n",
    "\n",
    "df = pd.DataFrame(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_DIR1+\"string_analysis_hypno.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmented post-trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_string(s, part_size=2700):\n",
    "    parts = [s[i*part_size:(i+1)*part_size] for i in range(4)]\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rat_id</th>\n",
       "      <th>study_day</th>\n",
       "      <th>condition</th>\n",
       "      <th>treatment</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>string_rem</th>\n",
       "      <th>string_phasic_tonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>HC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>HC</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNNNNNNNNNNNNNNNN...</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNNNNNNNNNNNNNNNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>HC</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>HC</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
       "      <td>NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>OR</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "      <td>WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rat_id  study_day condition  treatment trial_num  \\\n",
       "0       5          8        HC          0         3   \n",
       "1       5          8        HC          0         2   \n",
       "2       5          8        HC          0         4   \n",
       "3       5          8        HC          0         5   \n",
       "4       5         16        OR          1         5   \n",
       "\n",
       "                                          string_rem  \\\n",
       "0  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...   \n",
       "1  WWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNNNNNNNNNNNNNNNN...   \n",
       "2  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...   \n",
       "3  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...   \n",
       "4  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...   \n",
       "\n",
       "                                 string_phasic_tonic  \n",
       "0  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...  \n",
       "1  WWWWWWWWWWWWWWWWWWWWWWWWWWWWNNNNNNNNNNNNNNNNNN...  \n",
       "2  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...  \n",
       "3  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...  \n",
       "4  WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seg = df.copy()\n",
    "df_seg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = []\n",
    "for i, row in df_seg.iterrows():\n",
    "    if row['trial_num'] == '5':\n",
    "        #print(len(row['string_rem']))\n",
    "        parts_rem = partition_string(row['string_rem'])\n",
    "        parts_phrem = partition_string(row['string_phasic_tonic'])\n",
    "        for j, string_rem in enumerate(parts_rem):\n",
    "            row['trial_num'] = '5.' + str(j+1)\n",
    "            row['string_rem'] = string_rem\n",
    "            row['string_phasic_tonic'] = parts_phrem[j]\n",
    "            new_df.append(pd.DataFrame([row]))\n",
    "    else:\n",
    "        new_df.append(pd.DataFrame([row]))\n",
    "#df2 = pd.concat(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2=pd.concat(new_df, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2.to_csv(OUTPUT_DIR2+'string_analysis_hypno.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg = pd.read_csv(OUTPUT_DIR2+\"string_analysis_hypno.csv\", index_col=0)\n",
    "df_whole = pd.read_csv(OUTPUT_DIR1+\"string_analysis_hypno.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latency(string):\n",
    "    latencies = {}\n",
    "    if (\"P\" in string) or (\"T\" in string):\n",
    "        for state in [\"W\", \"N\", \"I\", \"P\", \"T\"]:\n",
    "            latencies[state] = string.find(state)\n",
    "    else:\n",
    "        for state in [\"W\", \"N\", \"I\", \"R\"]:\n",
    "            latencies[state] = string.find(state)\n",
    "    return latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = []\n",
    "for i, row in df_seg.iterrows():\n",
    "    latencies = compute_latency(row['string_rem'])\n",
    "    for state in latencies:\n",
    "        row[state] = latencies[state]\n",
    "    row['P'] = row['string_phasic_tonic'].find(\"P\")\n",
    "    row['T'] = row['string_phasic_tonic'].find(\"T\")\n",
    "    container.append(row)\n",
    "lat_df = pd.DataFrame(container)\n",
    "lat_df.to_csv(OUTPUT_DIR2+\"string_analysis_latency.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = []\n",
    "for i, row in df_whole.iterrows():\n",
    "    latencies = compute_latency(row['string_rem'])\n",
    "    for state in latencies:\n",
    "        row[state] = latencies[state]\n",
    "    row['P'] = row['string_phasic_tonic'].find(\"P\")\n",
    "    row['T'] = row['string_phasic_tonic'].find(\"T\")\n",
    "    container.append(row)\n",
    "lat_df = pd.DataFrame(container)\n",
    "lat_df.to_csv(OUTPUT_DIR1+\"string_analysis_latency.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
