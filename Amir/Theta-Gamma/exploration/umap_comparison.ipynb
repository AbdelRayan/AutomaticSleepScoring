{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialzing and loading required libraries and subfunctions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import yasa\n",
    "from mne.filter import resample\n",
    "import pynapple as nap\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import sails\n",
    "import re\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.signal import correlate\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.fft import fft\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.io import loadmat\n",
    "import scipy.fft\n",
    "import scipy.stats\n",
    "import scipy.io as sio\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "import emd as emd\n",
    "import emd.sift as sift\n",
    "import emd.spectra as spectra\n",
    "\n",
    "from neurodsp.sim import sim_combined\n",
    "from neurodsp.plts import plot_time_series, plot_timefrequency\n",
    "from neurodsp.utils import create_times\n",
    "from neurodsp.timefrequency.wavelets import compute_wavelet_transform\n",
    "from neurodsp.filt import filter_signal\n",
    "\n",
    "# Load required libraries\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import hilbert\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from neurodsp.filt import filter_signal, filter_signal_fir, design_fir_filter\n",
    "import emd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import copy\n",
    "import umap.umap_ as umap\n",
    "import skdim\n",
    "from scipy.spatial import cKDTree\n",
    "import pickle\n",
    "\n",
    "## UTILS\n",
    "from utils import *\n",
    "from detect_pt import *\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from neurodsp.filt import filter_signal\n",
    "import copy\n",
    "import emd\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set(style='white', context='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = emd.sift.SiftConfig.from_yaml_file('/Users/amir/Desktop/for Abdel/emd_masksift_CA1_config_2500.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pt_intervals(lfpHPC, hypno, fs=2500):\n",
    "    targetFs = 500\n",
    "    n_down = fs / targetFs\n",
    "    start, end = get_start_end(hypno=hypno, sleep_state_id=5)\n",
    "    rem_interval = nap.IntervalSet(start=start, end=end)\n",
    "    fs = int(n_down * targetFs)\n",
    "    t = np.arange(0, len(lfpHPC) / fs, 1 / fs)\n",
    "    lfp = nap.TsdFrame(t=t, d=lfpHPC, columns=['HPC'])\n",
    "\n",
    "    # Detect phasic intervals\n",
    "    lfpHPC_down = preprocess(lfpHPC, n_down)\n",
    "    phREM = detect_phasic(lfpHPC_down, hypno, targetFs)\n",
    "\n",
    "    # Create phasic REM IntervalSet\n",
    "    start, end = [], []\n",
    "    for rem_idx in phREM:\n",
    "        for s, e in phREM[rem_idx]:\n",
    "            start.append(s / targetFs)\n",
    "            end.append(e / targetFs)\n",
    "    phasic_interval = nap.IntervalSet(start, end)\n",
    "\n",
    "    # Calculate tonic intervals\n",
    "    tonic_interval = rem_interval.set_diff(phasic_interval)\n",
    "    print(f'Number of detected Tonic intrevals:{len(tonic_interval)}')\n",
    "    # Apply a 100 ms duration threshold to tonic intervals\n",
    "    min_duration = 0.1  # 100 ms in seconds\n",
    "    durations = tonic_interval['end'] - tonic_interval['start']\n",
    "    valid_intervals = durations >= min_duration\n",
    "    tonic_interval = nap.IntervalSet(tonic_interval['start'][valid_intervals], tonic_interval['end'][valid_intervals])\n",
    "    print(f'Number of detected Tonic intrevals after threshold:{len(tonic_interval)}')\n",
    "    return phasic_interval, tonic_interval, lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_data_for_rat_rgs(rat_id):\n",
    "    # Define the base path to your datasets\n",
    "    base_path = '/Users/amir/Desktop/for Abdel/RGS'\n",
    "    fs = 2500  # Sample frequency\n",
    "\n",
    "    # Initialize empty DataFrames for concatenation across all recordings and trials for the specified rat\n",
    "    all_combined_waveforms = pd.DataFrame()\n",
    "    all_combined_trials = pd.DataFrame()\n",
    "\n",
    "    rat_path = os.path.join(base_path, str(rat_id))\n",
    "\n",
    "    # Check if the specified rat folder exists\n",
    "    if not os.path.isdir(rat_path):\n",
    "        print(f\"Rat folder {rat_id} does not exist.\")\n",
    "        return None, None\n",
    "\n",
    "    # List all recording folders in the rat directory\n",
    "    recording_folders = [\n",
    "        f for f in os.listdir(rat_path)\n",
    "        if os.path.isdir(os.path.join(rat_path, f))\n",
    "    ]\n",
    "    # print(recording_folders)\n",
    "    if not recording_folders:\n",
    "        print(f\"No recording folders found for Rat {rat_id}.\")\n",
    "        return None, None\n",
    "\n",
    "    # Loop over each recording folder\n",
    "    for recording_folder in recording_folders:\n",
    "        print(f\"Processing recording folder: {recording_folder}\")\n",
    "        recording_path = os.path.join(rat_path, recording_folder)\n",
    "\n",
    "        # Adjusted regular expression to match your folder names\n",
    "        # match = re.match(r'^OS_Ephys_RGS14_(Rat\\d+)_57987_SD(\\d+)_(\\w+)_([\\d\\-_]+)$', recording_folder)\n",
    "        match = re.match(r'^OS_Ephys_RGS14_(Rat\\d+)_\\d+_SD(\\d+)_(\\w+)_([\\d\\-_]+)$', recording_folder)\n",
    "        if not match:\n",
    "            print(f\"Unexpected folder name format: {recording_folder}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        rat_id_part = match.group(1)       # e.g., 'Rat1'\n",
    "        sd_number = match.group(2)         # e.g., '1'\n",
    "        condition = match.group(3)         # e.g., 'CON', 'OD', 'OR', 'HC'\n",
    "        date_part = match.group(4)         # e.g., '27-28_07_2018'\n",
    "\n",
    "        rat_id_from_folder = ''.join(filter(str.isdigit, rat_id_part))\n",
    "\n",
    "        # Check if rat_id_from_folder matches rat_id\n",
    "        if rat_id_from_folder != str(rat_id):\n",
    "            print(f\"Rat ID mismatch in folder {recording_folder}. Expected Rat{rat_id}, found Rat{rat_id_from_folder}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Detect all trial folders matching 'Post-Trial2' to 'Post-Trial5'\n",
    "        trial_folders = [\n",
    "            f for f in os.listdir(recording_path)\n",
    "            if os.path.isdir(os.path.join(recording_path, f)) and\n",
    "            re.search(r'Post[\\-_]?Trial[\\-_]?([2-5])$', f, re.IGNORECASE)\n",
    "        ]\n",
    "\n",
    "        if not trial_folders:\n",
    "            print(f\"No trial folders found in {recording_folder}.\")\n",
    "            continue\n",
    "\n",
    "        for trial_folder in trial_folders:\n",
    "            print(f\"Processing trial folder: {trial_folder}\")\n",
    "            trial_path = os.path.join(recording_path, trial_folder)\n",
    "\n",
    "            # Search for LFP and state files in the trial folder\n",
    "            lfp_file = None\n",
    "            state_file = None\n",
    "\n",
    "            for file_name in os.listdir(trial_path):\n",
    "                if 'HPC_100' in file_name and file_name.endswith('.mat'):\n",
    "                    lfp_file = os.path.join(trial_path, file_name)\n",
    "                elif 'states' in file_name and file_name.endswith('.mat'):\n",
    "                    state_file = os.path.join(trial_path, file_name)\n",
    "                elif 'States' in file_name and file_name.endswith('.mat'):\n",
    "                    state_file = os.path.join(trial_path, file_name)\n",
    "\n",
    "            # Ensure both LFP and state files were found\n",
    "            if not lfp_file or not state_file:\n",
    "                print(f\"Missing LFP or state file in {trial_path}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Extract trial number from folder name\n",
    "            trial_number_match = re.search(r'Post[\\-_]?Trial[\\-_]?([2-5])$', trial_folder, re.IGNORECASE)\n",
    "            if trial_number_match:\n",
    "                trial_number = int(trial_number_match.group(1))\n",
    "            else:\n",
    "                print(f\"Unable to extract trial number from folder name: {trial_folder}. Skipping...\")\n",
    "                continue\n",
    "            # Load data using custom functions (ensure these functions are defined elsewhere)\n",
    "            try:\n",
    "                lfpHPC, hypno, _ = get_data(lfp_file, state_file)\n",
    "                # Extract phasic and tonic intervals, handling cases with no REM sleep\n",
    "                try:\n",
    "                    phasic_interval, tonic_interval, lfp = extract_pt_intervals(lfpHPC, hypno)\n",
    "                except ValueError as e:\n",
    "                    print(f\"No REM sleep found in {trial_folder} for Rat {rat_id}, Condition {condition}. Filling with empty intervals.\")\n",
    "                    phasic_interval, tonic_interval, lfp = [[], [], []]\n",
    "\n",
    "                # Extract IMFs and frequencies for phasic and tonic intervals if intervals are not empty\n",
    "                if phasic_interval and tonic_interval:\n",
    "                    # Assume 'config' is defined elsewhere in your code\n",
    "                    tonic_imfs, tonic_freqs, tonic_lpf = extract_imfs_by_pt_intervals(\n",
    "                        lfp, fs, tonic_interval, config, return_imfs_freqs=True)\n",
    "                    phasic_imfs, phasic_freqs, phasic_lpf = extract_imfs_by_pt_intervals(\n",
    "                        lfp, fs, phasic_interval, config, return_imfs_freqs=True)\n",
    "\n",
    "                    # Prepare UMAP data for both phasic and tonic\n",
    "                    phasic_waveforms, phasic_trials, _ = prepare_data_for_umap(phasic_imfs, phasic_freqs)\n",
    "                    tonic_waveforms, tonic_trials, _ = prepare_data_for_umap(tonic_imfs, tonic_freqs)\n",
    "\n",
    "                    # Add metadata columns, including cycle type labels\n",
    "                    for df in [phasic_waveforms, phasic_trials]:\n",
    "                        df['rat_id'] = rat_id\n",
    "                        df['condition'] = condition\n",
    "                        df['trial'] = trial_number\n",
    "                        df['cycle_type'] = 'phasic'\n",
    "                        df['SD'] = sd_number\n",
    "                        df['date'] = date_part\n",
    "\n",
    "                    for df in [tonic_waveforms, tonic_trials]:\n",
    "                        df['rat_id'] = rat_id\n",
    "                        df['condition'] = condition\n",
    "                        df['trial'] = trial_number\n",
    "                        df['cycle_type'] = 'tonic'\n",
    "                        df['SD'] = sd_number\n",
    "                        df['date'] = date_part\n",
    "\n",
    "                    # Concatenate into combined DataFrames\n",
    "                    all_combined_waveforms = pd.concat(\n",
    "                        [all_combined_waveforms, phasic_waveforms, tonic_waveforms], ignore_index=True)\n",
    "                    all_combined_trials = pd.concat(\n",
    "                        [all_combined_trials, phasic_trials, tonic_trials], ignore_index=True)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Data not found in {trial_path}. Skipping...\")\n",
    "\n",
    "    if all_combined_waveforms.empty:\n",
    "        print(f\"No data extracted for Rat {rat_id}.\")\n",
    "        return None, None\n",
    "\n",
    "    return all_combined_waveforms, all_combined_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rat folder 1 does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "rat_id = '1'\n",
    "waveforms_df, trials_df = extract_data_for_rat_rgs(rat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thetaGamma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
