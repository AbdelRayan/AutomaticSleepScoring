{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdelRayan/AutomaticSleepScoring/blob/main/Faranak/Faranak_Copy_of_SO_NREM_Substages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQlQiHNJW9Mc"
      },
      "source": [
        "\n",
        "# install and import required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3l7NHOWN8eSe"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install neurodsp\n",
        "!pip install emd\n",
        "!pip install tslearn\n",
        "!pip install dtaidistance\n",
        "!pip install sails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "73x8ARjmASgy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import hilbert\n",
        "from scipy.interpolate import interp1d\n",
        "import matplotlib.pyplot as plt\n",
        "from neurodsp.filt import filter_signal, filter_signal_fir, design_fir_filter\n",
        "import emd\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from tqdm import tqdm\n",
        "import plotly.express as px\n",
        "from tslearn.clustering import TimeSeriesKMeans, KShape\n",
        "from tslearn.metrics import dtw\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import copy\n",
        "import sails\n",
        "import requests\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca7hrzOxXDHG"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oAv0Khm8nC3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "5739b5ce-da7c-4c78-c625-2a8b58e1e2a7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-91874b305a32>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWYHlaXksYGw"
      },
      "outputs": [],
      "source": [
        "# # Loading sleep scoring data from MAT files stored in Google Drive.\n",
        "#path_to_pt5 = '/content/drive/My Drive/Donders/Datasets/2020-04-21_15-00-06_Post_Trial5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZSAn5naxpNc"
      },
      "outputs": [],
      "source": [
        "#pfc_cleaned = loadmat(path_to_pt5 + '/PFC_cleaned.mat')\n",
        "#pfc_cleaned = pfc_cleaned['PFClfpCleaned']\n",
        "#pfc_cleaned = pfc_cleaned[8*1000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTzU67xLoBus"
      },
      "outputs": [],
      "source": [
        "# sleep_scoring = loadmat(path_to_pt5 + '/2020-04-21_15-00-06_Post_Trial5-states.mat')\n",
        "# sleep_scoring = sleep_scoring['states']\n",
        "# sleep_scoring = sleep_scoring[0, 7:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7pHlL0vvEqb"
      },
      "outputs": [],
      "source": [
        "# pfc_data = pfc_cleaned.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRke0iEoPYu3"
      },
      "source": [
        "## RGS14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-0-fVkC9-nY"
      },
      "outputs": [],
      "source": [
        "# # link to DropBox: https://www.dropbox.com/scl/fo/43ygu24t4pwwpvrgaimdj/h/3/Study_day_3_HC/post_trial5_2017-11-15_14-04-39?dl=0&subfolder_nav_tracking=1\n",
        "# #\n",
        "\n",
        "# url_pfc_RGS14 = \"https://www.dropbox.com/scl/fo/43ygu24t4pwwpvrgaimdj/h/3/Study_day_3_HC/post_trial5_2017-11-15_14-04-39/PFC_100_CH49.continuous.mat?rlkey=5n19vud9g3fcleaehkfgmvjyn&dl=1\"\n",
        "\n",
        "url_pfc_RGS14 = 'https://www.dropbox.com/scl/fo/43ygu24t4pwwpvrgaimdj/h/13/2019-05-15_SD2_HC_Rat13_344994/2019-05-15_14-08-14_Post-Trial5/PFC_100_CH63_0.continuous.mat?rlkey=5n19vud9g3fcleaehkfgmvjyn&dl=1'\n",
        "\n",
        "response_RGS14 = requests.get(url_pfc_RGS14)\n",
        "response_RGS14.raise_for_status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gn1FRbgAZbp"
      },
      "outputs": [],
      "source": [
        "#state_response_url_RGS14 = 'https://www.dropbox.com/scl/fo/43ygu24t4pwwpvrgaimdj/h/3/Study_day_3_HC/post_trial5_2017-11-15_14-04-39/post_trial5_2017-11-15_14-04-39-states.mat?rlkey=5n19vud9g3fcleaehkfgmvjyn&dl=1'\n",
        "state_respomse_url_RGS14 = 'https://www.dropbox.com/scl/fo/43ygu24t4pwwpvrgaimdj/h/13/2019-05-15_SD2_HC_Rat13_344994/2019-05-15_14-08-14_Post-Trial5/2019-05-15_14-08-14_Post-Trial5-states.mat?rlkey=5n19vud9g3fcleaehkfgmvjyn&dl=1'\n",
        "state_response_RGS14 = requests.get(state_respomse_url_RGS14)\n",
        "state_response_RGS14.raise_for_status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhWHP8m5-VW4"
      },
      "outputs": [],
      "source": [
        "PFC_100_CH49_RGS = scipy.io.loadmat(BytesIO(response_RGS14.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE46106YApX8"
      },
      "outputs": [],
      "source": [
        "posttrial5_states_ES2_RGS = scipy.io.loadmat(BytesIO(state_response_RGS14.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-PFLsIu-eWn"
      },
      "outputs": [],
      "source": [
        "lfp_RGS14 = np.squeeze(PFC_100_CH49_RGS['PFC'])\n",
        "states_RGS14 = np.squeeze(posttrial5_states_ES2_RGS['states'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(len(states_RGS14)):\n",
        "  if states_RGS14[idx] == 0:\n",
        "    print(idx)"
      ],
      "metadata": {
        "id": "BZJrdPTBT_oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lfp_RGS14 = lfp_RGS14[7*2500:-11*2500]\n",
        "states_RGS14 = states_RGS14[:-11]"
      ],
      "metadata": {
        "id": "Txhc0cg8UP7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(len(states_RGS14)):\n",
        "  if states_RGS14[idx] == 0:\n",
        "    print(idx)"
      ],
      "metadata": {
        "id": "yKYkCXVzUZND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QB0nC0JYNT1"
      },
      "outputs": [],
      "source": [
        "len(lfp_RGS14)//1000//60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tmru88gau2D"
      },
      "outputs": [],
      "source": [
        "len(states_RGS14)//60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-p6iKRwPafL"
      },
      "source": [
        "## CBD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrkbEzbCPiOT"
      },
      "outputs": [],
      "source": [
        "# link to DropBox: https://www.dropbox.com/scl/fo/vk9sq7tky0mr2z0saf96h/ABZvpB4wKf2N3EPT-CVimbU/3/Rat_OS_Ephys_cbd_chronic_Rat3_407698_SD2_HC_20210603/2021-06-03_13-34-04_posttrial5?dl=0&rlkey=j12mjuudr49jcb18c68rzxe24&subfolder_nav_tracking=1\n",
        "#\n",
        "\n",
        "url_pfc_CBD = \"https://www.dropbox.com/scl/fo/vk9sq7tky0mr2z0saf96h/ALbOaCWN4JJJ-3Vr_XBthTs/3/Rat_OS_Ephys_cbd_chronic_Rat3_407698_SD2_HC_20210603/2021-06-03_13-34-04_posttrial5/PFC_100_CH22_0.continuous.mat?rlkey=j12mjuudr49jcb18c68rzxe24&dl=1\"\n",
        "\n",
        "response_CBD = requests.get(url_pfc_CBD)\n",
        "response_CBD.raise_for_status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vECBjz_SPiOT"
      },
      "outputs": [],
      "source": [
        "state_response_url_CBD = 'https://www.dropbox.com/scl/fo/vk9sq7tky0mr2z0saf96h/ABCU-y3YXyh9dBzp22RUaJw/3/Rat_OS_Ephys_cbd_chronic_Rat3_407698_SD2_HC_20210603/2021-06-03_13-34-04_posttrial5/2021-06-03_13-34-04_posttrial5-states_ES2.mat?rlkey=j12mjuudr49jcb18c68rzxe24&dl=1'\n",
        "state_response_CBD = requests.get(state_response_url_CBD)\n",
        "state_response_CBD.raise_for_status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OHB9WcaPiOU"
      },
      "outputs": [],
      "source": [
        "PFC_100_CH22_CBD = scipy.io.loadmat(BytesIO(response_CBD.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoXaexFyPiOU"
      },
      "outputs": [],
      "source": [
        "posttrial5_states_ES2_CBD = scipy.io.loadmat(BytesIO(state_response_CBD.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR38EqtxPiOU"
      },
      "outputs": [],
      "source": [
        "lfp_CBD = np.squeeze(PFC_100_CH22_CBD['PFC'])\n",
        "states_CBD = np.squeeze(posttrial5_states_ES2_CBD['states'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi-FCmCbX8aV"
      },
      "outputs": [],
      "source": [
        "len(lfp_CBD)/2500/60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIzEsweYYXw7"
      },
      "outputs": [],
      "source": [
        "len(states_CBD)/60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOCiRVPaYX_M"
      },
      "source": [
        "## OS Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib45wg0pYX_N"
      },
      "outputs": [],
      "source": [
        "# link to DropBox: https://www.dropbox.com/scl/fo/dw1kw8acsna3qponvydwy/h/1/HC/post_trial5_2017-09-27_14-18-24?dl=0&subfolder_nav_tracking=1\n",
        "#\n",
        "\n",
        "#url_pfc_OSB = \"https://www.dropbox.com/scl/fo/dw1kw8acsna3qponvydwy/h/1/HC/post_trial5_2017-09-27_14-18-24/PFC_100_CH11.continuous.mat?rlkey=hs1o7bequxipnl1m8eii7eibu&dl=1\"\n",
        "url_pfc_OSB = \"https://www.dropbox.com/scl/fo/dw1kw8acsna3qponvydwy/h/6/Study_day6_HC_28feb2018/Post_trial5_2018-02-28_13-42-34/PFC_100_CH33.continuous.mat?rlkey=hs1o7bequxipnl1m8eii7eibu&dl=1\"\n",
        "response_OSB = requests.get(url_pfc_OSB)\n",
        "response_OSB.raise_for_status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnpUG3k_YX_N"
      },
      "outputs": [],
      "source": [
        "#state_response_url_OSB = 'https://www.dropbox.com/scl/fo/dw1kw8acsna3qponvydwy/h/1/HC/post_trial5_2017-09-27_14-18-24/post_trial5_2017-09-27_14-18-24-states.mat?rlkey=hs1o7bequxipnl1m8eii7eibu&dl=1'\n",
        "state_response_url_OSB = 'https://www.dropbox.com/scl/fo/dw1kw8acsna3qponvydwy/h/6/Study_day6_HC_28feb2018/Post_trial5_2018-02-28_13-42-34/post_trial5_2018-02-28_13-42-34-states.mat?rlkey=hs1o7bequxipnl1m8eii7eibu&dl=1'\n",
        "state_response_OSB = requests.get(state_response_url_OSB)\n",
        "state_response_OSB.raise_for_status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54ctYa62YX_N"
      },
      "outputs": [],
      "source": [
        "PFC_100_CH11_OSB = scipy.io.loadmat(BytesIO(response_OSB.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4Ra_FXfYX_N"
      },
      "outputs": [],
      "source": [
        "posttrial5_states_ES2_OSB = scipy.io.loadmat(BytesIO(state_response_OSB.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e_kdjiNYX_N"
      },
      "outputs": [],
      "source": [
        "lfp_OSB = np.squeeze(PFC_100_CH11_OSB['PFC'])\n",
        "states_OSB = np.squeeze(posttrial5_states_ES2_OSB['states'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(len(states_OSB)):\n",
        "  if states_OSB[idx] == 0:\n",
        "    print(idx)"
      ],
      "metadata": {
        "id": "9Q-03yOUQznb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lfp_OSB = lfp_OSB[7*2500:-11*2500]\n",
        "states_OSB = states_OSB[7:-11]"
      ],
      "metadata": {
        "id": "tGFv0ASuROuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(len(states_OSB)):\n",
        "  if states_OSB[idx] == 0:\n",
        "    print(idx)"
      ],
      "metadata": {
        "id": "-miFUmDbRXxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(states_OSB)/60"
      ],
      "metadata": {
        "id": "PB4PN_LsRb1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD1YzRJLYX_N"
      },
      "outputs": [],
      "source": [
        "len(lfp_OSB)/2500/60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKq9XbACbKXC"
      },
      "outputs": [],
      "source": [
        "len(states_OSB)/60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvnoB9VvXH1C"
      },
      "source": [
        "# RGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSeK5EPsAozc"
      },
      "outputs": [],
      "source": [
        "def find_all_NREM_epochs(arr):\n",
        "    nrem_epochs = []\n",
        "    start_index = None\n",
        "\n",
        "    for i, num in enumerate(arr):\n",
        "        if num == 3:\n",
        "            if start_index is None:\n",
        "                start_index = i\n",
        "        elif num != 3 and start_index is not None:\n",
        "            nrem_epochs.append([start_index, i - 1])\n",
        "            start_index = None\n",
        "\n",
        "    if start_index is not None:\n",
        "        nrem_epochs.append([start_index, len(arr) - 1])\n",
        "\n",
        "    return nrem_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axeUPOrQAsKv"
      },
      "outputs": [],
      "source": [
        "def peak_before_trough(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 1, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return arr[i]\n",
        "  return -1\n",
        "\n",
        "def peak_before_trough_pos(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 1, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return i\n",
        "  return -1\n",
        "\n",
        "def peak_to_trough_duration(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 20, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return trough_pos-i\n",
        "  return -1\n",
        "\n",
        "def num_inflection_points(arr):\n",
        "  sign_changes = np.diff(np.sign(np.diff(arr, 2)))\n",
        "  num_inflection_points = np.sum(sign_changes != 0)\n",
        "  return num_inflection_points\n",
        "\n",
        "def compute_range(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "def asc2desc(x):\n",
        "    pt = emd.cycles.cf_peak_sample(x, interp=True)\n",
        "    tt = emd.cycles.cf_trough_sample(x, interp=True)\n",
        "    if (pt is None) or (tt is None):\n",
        "        return np.nan\n",
        "    asc = pt + (len(x) - tt)\n",
        "    desc = tt - pt\n",
        "    return asc / len(x)\n",
        "\n",
        "def peak2trough(x):\n",
        "    des = emd.cycles.cf_descending_zero_sample(x, interp=True)\n",
        "    if des is None:\n",
        "        return np.nan\n",
        "    return des / len(x)\n",
        "\n",
        "# Compute metrics for each cycle -\n",
        "def get_cycles_with_metrics(cycles, data, IA, IF, conditions=None):\n",
        "  C = copy.deepcopy(cycles)\n",
        "\n",
        "  C.compute_cycle_metric('duration_samples', data, func=len)\n",
        "  C.compute_cycle_metric('peak2trough', data, func=peak2trough)\n",
        "  C.compute_cycle_metric('asc2desc', data, func=asc2desc)\n",
        "  C.compute_cycle_metric('max_amp', IA, func=np.max)\n",
        "  C.compute_cycle_metric('trough_values', data, func=np.min)\n",
        "  C.compute_cycle_metric('peak_values', data, func=np.max)\n",
        "  C.compute_cycle_metric('mean_if', IF, func=np.mean)\n",
        "  C.compute_cycle_metric('max_if', IF, func=np.max)\n",
        "  C.compute_cycle_metric('range_if', IF, func=compute_range)\n",
        "\n",
        "  C.compute_cycle_metric('trough_position', data, func=np.argmin)\n",
        "  C.compute_cycle_metric('peak_position', data, func=np.argmax)\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J88LnIhBoRR"
      },
      "outputs": [],
      "source": [
        "nrem_epochs = find_all_NREM_epochs(states_RGS14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRN6-vLGEiSd"
      },
      "outputs": [],
      "source": [
        "nrem_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EBMo5M7pVBV"
      },
      "outputs": [],
      "source": [
        "a = np.diff(nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlSh2vU4pYJz"
      },
      "outputs": [],
      "source": [
        "b = a[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFh6tVLfpdWd"
      },
      "outputs": [],
      "source": [
        "sum(b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lfp_RGS14)/1000/60"
      ],
      "metadata": {
        "id": "Nd-ukpz2lqAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining all the NREM epochs and filtering the Delta band\n",
        "\n",
        "fs = 1000 # Sampling rate/frequency\n",
        "nrem_data_RGS = []\n",
        "for start, end in nrem_epochs:\n",
        "  pfc_data_part_RGS = lfp_RGS14[start*fs:end*fs]\n",
        "  nrem_data_RGS.extend(pfc_data_part_RGS)\n",
        "nrem_data_RGS = np.array(nrem_data_RGS)"
      ],
      "metadata": {
        "id": "innYubN02asg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cut_off = 20\n",
        "# fs = 1000\n",
        "\n",
        "# n_cycles = 5\n",
        "\n",
        "# low_sig, filter_coefs = filter_signal_fir(\n",
        "#     sig=nrem_data,\n",
        "#     fs=fs,\n",
        "#     pass_type='lowpass',\n",
        "#     f_range=cut_off,\n",
        "#     n_cycles=n_cycles,\n",
        "#     remove_edges=True,  #\n",
        "#     print_transitions=True,\n",
        "#     plot_properties=True,  #\n",
        "#     return_filter=True\n",
        "# )"
      ],
      "metadata": {
        "id": "xa_W6_o32eV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs"
      ],
      "metadata": {
        "id": "QJt9YXsTSBky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUcrF0W2AxxF"
      },
      "outputs": [],
      "source": [
        "#nrem_filtered_data = filter_signal(nrem_data, fs, 'bandpass', (0.1, 4), n_cycles=3, filter_type='iir', butterworth_order=6, remove_edges=False)\n",
        "nrem_filtered_data = filter_signal_fir(nrem_data_RGS, fs,\n",
        "                                       'bandpass', (0.1, 4),\n",
        "                                       n_cycles=3, remove_edges=False,\n",
        "                                       print_transitions=True, plot_properties=True)\n",
        "# For testing, subset data\n",
        "# nrem_filtered_data = nrem_filtered_data[:fs*60*10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4l0Hv2pI0Qg"
      },
      "outputs": [],
      "source": [
        "# Extract Instantaneous phase (IP), frequency and amplitude (from Hilbert Transform)\n",
        "IP, IF, IA = emd.spectra.frequency_transform(nrem_filtered_data, fs, 'hilbert')\n",
        "\n",
        "# Get cycles using IP\n",
        "C = emd.cycles.Cycles(IP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZMQIu2mPZon"
      },
      "outputs": [],
      "source": [
        "cycles = get_cycles_with_metrics(C, nrem_filtered_data, IA, IF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AemmQsbV8Szl"
      },
      "outputs": [],
      "source": [
        "def get_cycles_with_conditions(cycles, fs, conditions):\n",
        "  C = copy.deepcopy(cycles)\n",
        "  metrics = C.get_metric_dataframe()\n",
        "\n",
        "  amp_thresh = np.percentile(IA, 25) # 25th percentile of the amplitude\n",
        "  peak_thresh = np.percentile(metrics['peak_values'], 85)\n",
        "  trough_thresh = np.percentile(metrics['trough_values'], 40)\n",
        "\n",
        "  lo_freq_duration = fs/0.1\n",
        "  hi_freq_duration = fs/4\n",
        "\n",
        "  C.pick_cycle_subset(conditions)\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNAAvteTQ49X"
      },
      "outputs": [],
      "source": [
        "metrics = cycles.get_metric_dataframe()\n",
        "amp_thresh = np.percentile(IA, 25) # 25th percentile of the amplitude\n",
        "peak_thresh = np.percentile(metrics['peak_values'], 85)\n",
        "trough_thresh = np.percentile(metrics['trough_values'], 40)\n",
        "lo_freq_duration = fs/0.1\n",
        "hi_freq_duration = fs/4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAzDB24eDk21"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              # f'peak_values>={peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "all_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CPLQZBXPuYX"
      },
      "outputs": [],
      "source": [
        "all_metrics = all_cycles.get_metric_dataframe(subset=True)\n",
        "all_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMprtcZqDMnV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abge7flnN5tM"
      },
      "source": [
        "## Get SO and delta cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf2pgR_p9CEm"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              f'peak_values>={peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "so_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPnzSCBo9o0Z"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              f'peak_values<{peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "delta_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvBDqNMED2as"
      },
      "outputs": [],
      "source": [
        "metrics_so = so_cycles.get_metric_dataframe(subset=True)\n",
        "metrics_delta = delta_cycles.get_metric_dataframe(subset=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oob3SVcNCP0E"
      },
      "source": [
        "## Rate of SO and delta cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcGahIWnEs9i"
      },
      "outputs": [],
      "source": [
        "def get_masked_cycles(IP, cycles):\n",
        "  mask = np.full(cycles.nsamples, False)\n",
        "  subset_cycles = cycles.get_metric_dataframe(subset=True)['index']\n",
        "\n",
        "  for i in subset_cycles:\n",
        "    inds = cycles.get_inds_of_cycle(i)\n",
        "    mask[inds] = True\n",
        "\n",
        "  masked_so_cycles = emd.cycles.get_cycle_vector(IP, mask=mask)\n",
        "  return masked_so_cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFhlTnJDGxUV"
      },
      "outputs": [],
      "source": [
        "def rate_cycle(cycles_vector, duration=1, fs=1000):\n",
        "  samples_per_segment = duration * fs\n",
        "  segments = np.array_split(cycles_vector, np.arange(samples_per_segment, len(cycles_vector), samples_per_segment))\n",
        "  segments = np.array(segments[:-1])\n",
        "\n",
        "  rate = []\n",
        "  for segment in segments:\n",
        "    if -1 in segment:\n",
        "      rate.append(len(np.unique(segment))-1)\n",
        "    else:\n",
        "      rate.append(len(np.unique(segment)))\n",
        "  rate = np.array(rate)\n",
        "  rate = rate/duration\n",
        "  return rate, segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bradY4KEeTj"
      },
      "outputs": [],
      "source": [
        "so_cycles_vector = get_masked_cycles(IP, so_cycles)\n",
        "delta_cycles_vector = get_masked_cycles(IP, delta_cycles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSQjNTmuIbRe"
      },
      "source": [
        "## 3s window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF8Z-o2plx53"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate, _ = rate_cycle(so_cycles_vector, duration=3, fs=1000)\n",
        "delta_cycles_rate, _ = rate_cycle(delta_cycles_vector, duration=3, fs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y23JPCShSf5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.title('SO - Upper 15th Percentile - RGS')\n",
        "plt.bar(range(len(so_cycles_rate)), so_cycles_rate)\n",
        "plt.ylabel(\"Rate of SOs (Hz)\")\n",
        "plt.xlabel(\"Time (3 sec windows)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5Tq7PG7m_GL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "plt.xlabel('Rates')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - window: 3s - Upper 50th Percentile')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LFvElgfncTo"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "\n",
        "min_x = min(so_cycles_rate)\n",
        "max_x = max(so_cycles_rate)\n",
        "x_ticks = np.arange(min_x, max_x + 0.1, 0.1)\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "plt.xlabel('Rates (window: 3s)')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - RGS')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUcZZecDEUOk"
      },
      "outputs": [],
      "source": [
        "def score_rates(so_cycles_rate):\n",
        "\n",
        "  score_array = np.zeros_like(so_cycles_rate)\n",
        "  for idx in range(len(so_cycles_rate)):\n",
        "    if so_cycles_rate[idx] < 0.2:\n",
        "      score_array[idx] = 1\n",
        "    elif so_cycles_rate[idx] <=0.8 and so_cycles_rate[idx]  >= 0.2:\n",
        "      score_array[idx] = 2\n",
        "    else:\n",
        "      score_array[idx] = 3\n",
        "  return score_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyymTbo9Fhlp"
      },
      "outputs": [],
      "source": [
        "score_array = score_rates(so_cycles_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y9sM_R6_-XY"
      },
      "outputs": [],
      "source": [
        "np.unique(score_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW-In9rTFlRl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score - Upper 50th Percentile')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time - window: 3s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5ttXMuXHyxV"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(score_array, return_counts=True)\n",
        "percentages = counts / len(score_array) * 100\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"N1\", \"N2\", \"N3\"], color=['b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage (window: 3)')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of light and deep stages - Upper 15th Percentile - RGS'\n",
        "plt.title(titlee)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5egJHQTJoMEs"
      },
      "source": [
        "### Criterias for merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpNY-NjNKCcM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQfZ0yADqVFD"
      },
      "outputs": [],
      "source": [
        "NREM_recunstruct = []\n",
        "\n",
        "for score in score_array:\n",
        "  for _ in range(3):\n",
        "    NREM_recunstruct.append(score)\n",
        "NREM_recunstruct.append(score_array[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grTC7xZXqY8Q"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xig0VLzcq10O"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(NREM_recunstruct):\n",
        "    NREM_recunstruct[i] = score + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-S2gRephrNpq"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt4xcAs9rc34"
      },
      "outputs": [],
      "source": [
        "def make_new_scoring(sleep_scoring, new_nrem, nrem_epochs):\n",
        "    sleep_array = np.array(sleep_scoring)\n",
        "    i = 0\n",
        "    for start, end in nrem_epochs:\n",
        "        segment_length = end - start\n",
        "        sleep_array[start:end] = new_nrem[i:i + segment_length]\n",
        "        i += segment_length\n",
        "    return sleep_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNa1zEy2tbtp"
      },
      "outputs": [],
      "source": [
        "final_scores = make_new_scoring(states_RGS14, NREM_recunstruct, nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czkhsAih-l70"
      },
      "outputs": [],
      "source": [
        "len(final_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJQwCWvTu88t"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(final_scores)):\n",
        "  if final_scores[i] == 3:\n",
        "    final_scores[i] = final_scores[i - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_1uV38F0PTo"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(final_scores):\n",
        "  if score == 6:\n",
        "    final_scores[i] = 2\n",
        "  elif score == 7:\n",
        "    final_scores[i] = 3\n",
        "  elif score == 8:\n",
        "    final_scores[i] = 4\n",
        "  elif score == 4:\n",
        "    final_scores[i] = 5\n",
        "  elif score == 5:\n",
        "    final_scores[i] = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJL-o6PluoAC"
      },
      "outputs": [],
      "source": [
        "score_labels = {1: 'Wake', 2:'N1', 3:'N2', 4:'N3', 5: 'Intermediate', 6: 'REM'}\n",
        "num_labels = {label: num for num, label in enumerate(score_labels.values(), start=1)}\n",
        "plt.figure(figsize=(16, 8))\n",
        "time_minutes = np.arange(0, len(final_scores)) / 60\n",
        "plt.step(time_minutes,final_scores)\n",
        "plt.title('Hypnogram of whole sleep - Upper 15th Percentile - RGS')\n",
        "plt.yticks(list(num_labels.values()), list(score_labels.values()))\n",
        "plt.xlabel(\"Time (minutes) - (3s window)\")\n",
        "plt.savefig('hypnogram_3s_15th.svg', format='svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(final_scores, return_counts=True)"
      ],
      "metadata": {
        "id": "9B51D9n5TyNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique"
      ],
      "metadata": {
        "id": "5Z8v_1_YTzln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLHWxEMUuQFy"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(final_scores, return_counts=True)\n",
        "percentages = counts / len(final_scores) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"Wake\", 'N1', 'N2', 'N3', 'Intermediate', 'REM'], color=['b', 'b', 'b', 'b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage (3s window)')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of sleep stages - Upper 15th Percentile - RGS'\n",
        "plt.title(titlee)\n",
        "plt.savefig('Percentage-3s-15th.svg', format='svg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgQhsszu-g11"
      },
      "outputs": [],
      "source": [
        "f_lowpass = 20\n",
        "band = (0.1, 4)\n",
        "n_cycles = 3\n",
        "low_sig = filter_signal_fir(pfc_data, fs, 'lowpass', f_lowpass, n_cycles=n_cycles, remove_edges=False)\n",
        "delta_signal = filter_signal_fir(low_sig, fs, 'bandpass', band, n_cycles=n_cycles, remove_edges=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R1DibenVFhB"
      },
      "outputs": [],
      "source": [
        "np.unique(final_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zi-fsnczm-G"
      },
      "outputs": [],
      "source": [
        "def upscale_score(score_array, fs=1000):\n",
        "  scores = []\n",
        "  for i in range(len(score_array)):\n",
        "    for _ in range(fs):\n",
        "      scores.append(score_array[i])\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUSJYKBSvVdY"
      },
      "outputs": [],
      "source": [
        "def extract_n2_episodes(sleep_stages):\n",
        "    sleep_stages = np.asarray(sleep_stages).flatten()\n",
        "    n2_indices = np.where(sleep_stages == 3)[0]\n",
        "\n",
        "    episodes = []\n",
        "    if len(n2_indices) == 0:\n",
        "        return episodes\n",
        "\n",
        "    start_idx = None\n",
        "    for i in range(len(n2_indices)):\n",
        "        if start_idx is None:\n",
        "            start_idx = n2_indices[i]\n",
        "        if i == len(n2_indices) - 1 or n2_indices[i + 1] != n2_indices[i] + 1:\n",
        "            end_idx = n2_indices[i]\n",
        "            episodes.append((start_idx, end_idx))\n",
        "            start_idx = None\n",
        "\n",
        "    return episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrmPhiaBwgRk"
      },
      "outputs": [],
      "source": [
        "def extract_n3_episodes(sleep_stages):\n",
        "    sleep_stages = np.asarray(sleep_stages).flatten()\n",
        "    n3_indices = np.where(sleep_stages == 4)[0]\n",
        "\n",
        "    episodes = []\n",
        "    if len(n3_indices) == 0:\n",
        "        return episodes\n",
        "\n",
        "    start_idx = None\n",
        "    for i in range(len(n3_indices)):\n",
        "        if start_idx is None:\n",
        "            start_idx = n3_indices[i]\n",
        "        if i == len(n3_indices) - 1 or n3_indices[i + 1] != n3_indices[i] + 1:\n",
        "            end_idx = n3_indices[i]\n",
        "            episodes.append((start_idx, end_idx))\n",
        "            start_idx = None\n",
        "\n",
        "    return episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrXAymlZ29Rv"
      },
      "outputs": [],
      "source": [
        "nrem_signal_segment = delta_signal[start*fs: end*fs]\n",
        "score_segment = final_scores[start:end]\n",
        "upscaled_scores = upscale_score(score_segment, fs=1000)\n",
        "\n",
        "batch_length = 20\n",
        "\n",
        "total_batches = int(np.ceil(len(nrem_signal_segment) / (batch_length * fs)))\n",
        "print(start, ' ', end)\n",
        "print(total_batches)\n",
        "for i in range(total_batches):\n",
        "    batch_start_idx = i * batch_length * fs\n",
        "    batch_end_idx = min((i + 1) * batch_length * fs, len(nrem_signal_segment))\n",
        "\n",
        "    twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "    twenty_sec_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "    n2_episodes = extract_n2_episodes(twenty_sec_stages)\n",
        "    n3_episodes = extract_n3_episodes(twenty_sec_stages)\n",
        "\n",
        "    t = np.arange(0, len(twenty_sec_sig) / fs, 1/fs)\n",
        "\n",
        "    plt.figure(figsize=(16, 4.5))\n",
        "\n",
        "    plt.plot(t, twenty_sec_sig, color='black', label='N1')\n",
        "\n",
        "    for start_idx, end_idx in n2_episodes:\n",
        "        plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "    for start_idx, end_idx in n3_episodes:\n",
        "        plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.title('Filtered Signal with Sleep Stages Highlighted - filtered between 0.5 to 4Hz')\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    plt.legend(by_label.values(), by_label.keys())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUgXL4bQ5f_x"
      },
      "outputs": [],
      "source": [
        "def plot_nrem(signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    nrem_signal_segment = signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    # Calculate total number of batches\n",
        "    total_batches = int(np.ceil(len(nrem_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        # Determine batch start and end indices\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(nrem_signal_segment))\n",
        "\n",
        "        # Extract the signal and stages for the current batch\n",
        "        twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        twenty_sec_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        # Extract N2 and N3 episodes\n",
        "        n2_episodes = extract_n2_episodes(twenty_sec_stages)\n",
        "        n3_episodes = extract_n3_episodes(twenty_sec_stages)\n",
        "        print(n2_episodes)\n",
        "        print(n3_episodes)\n",
        "        # Generate time array dynamically based on the actual length of the segment\n",
        "        t = np.arange(0, len(twenty_sec_sig) / fs, 1/fs)\n",
        "\n",
        "        # Plot the signal with sleep stages highlighted\n",
        "        plt.figure(figsize=(16, 4.5))\n",
        "        plt.plot(t, twenty_sec_sig, color='black', label='N1')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1}')\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJFznoXI5xGf"
      },
      "outputs": [],
      "source": [
        "plot_nrem(delta_signal, final_scores, start, end, batch_length=20, fs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNonLK28WpdX"
      },
      "outputs": [],
      "source": [
        "def plot_nrem2(filtered_signal, raw_signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    filtered_signal_segment = filtered_signal[start * fs: end * fs]\n",
        "    raw_signal_segment = raw_signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    total_batches = int(np.ceil(len(filtered_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(filtered_signal_segment))\n",
        "\n",
        "        filtered_batch_sig = filtered_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        raw_batch_sig = raw_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        batch_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        n2_episodes = extract_n2_episodes(batch_stages)\n",
        "        n3_episodes = extract_n3_episodes(batch_stages)\n",
        "\n",
        "        t = np.arange(0, len(filtered_batch_sig) / fs, 1/fs)\n",
        "\n",
        "        plt.figure(figsize=(16, 9))\n",
        "\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(t, filtered_batch_sig, color='black', label='N1 (Filtered)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Filtered)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Filtered)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Filtered)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(t, raw_batch_sig, color='black', label='N1 (Raw)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Raw)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Raw)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)-3s-15th.svg', format='svg')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64jDj1LwZftE"
      },
      "outputs": [],
      "source": [
        "start, end = nrem_epochs[31]\n",
        "print(start, end)\n",
        "print((end - start + 1)/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQJASqhqWrro"
      },
      "outputs": [],
      "source": [
        "plot_nrem2(delta_signal, pfc_data, final_scores, start, end, 30, fs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZjaaEFAIpIY"
      },
      "source": [
        "## 10s window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2_DZ6mVIzIH"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate, _ = rate_cycle(so_cycles_vector, duration=10, fs=1000)\n",
        "delta_cycles_rate, _ = rate_cycle(delta_cycles_vector, duration=10, fs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75CcensWIzII"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.title('SO - Upper 15th Percentile - RGS')\n",
        "plt.bar(range(len(so_cycles_rate)), so_cycles_rate)\n",
        "plt.ylabel(\"Rate of SOs (Hz)\")\n",
        "plt.xlabel(\"Time (10 sec windows)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEKU3-VDIzII"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "ax = sns.kdeplot(so_cycles_rate, fill=True)\n",
        "\n",
        "ax.set_xlabel('Rates')\n",
        "ax.set_ylabel('Density')\n",
        "\n",
        "ax.set_title('Distribution of Rates - window: 10s - upper 15th percentile')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od3I5yoQIzII"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "plt.xlabel('Rates')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - window: 3s')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpZD6PTRIzIJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "\n",
        "min_x = min(so_cycles_rate)\n",
        "max_x = max(so_cycles_rate)\n",
        "x_ticks = np.arange(min_x, max_x + 0.1, 0.1)\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "plt.xlabel('Rates (window: 10s)')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - RGS')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoAoOXppIzIJ"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1ST9KKsIzIJ"
      },
      "outputs": [],
      "source": [
        "def score_rates(so_cycles_rate):\n",
        "\n",
        "  score_array = np.zeros_like(so_cycles_rate)\n",
        "  for idx in range(len(so_cycles_rate)):\n",
        "    if so_cycles_rate[idx] < 0.2:\n",
        "      score_array[idx] = 1\n",
        "    elif so_cycles_rate[idx] <=0.6 and so_cycles_rate[idx]  >= 0.2:\n",
        "      score_array[idx] = 2\n",
        "    else:\n",
        "      score_array[idx] = 3\n",
        "  return score_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXN3S9KSIzIJ"
      },
      "outputs": [],
      "source": [
        "score_array = score_rates(so_cycles_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PLJFCbZIzIJ"
      },
      "outputs": [],
      "source": [
        "np.unique(score_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUCM_ATZIzIJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score - window: 10s')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8DouPHTIzIJ"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(score_array, return_counts=True)\n",
        "percentages = counts / len(score_array) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"N1\", \"N2\", \"N3\"], color=['b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of light and deep stages - window: 10s - RGS'\n",
        "plt.title(titlee)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ocfiFGaIzIJ"
      },
      "source": [
        "## Criterias for merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCbk3mEEIzIJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C87zhmGaIzIK"
      },
      "outputs": [],
      "source": [
        "NREM_recunstruct = []\n",
        "\n",
        "for score in score_array:\n",
        "  for _ in range(10):\n",
        "    NREM_recunstruct.append(score)\n",
        "for i in range(8):\n",
        "  NREM_recunstruct.append(score_array[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaqcdjBhIzIK"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOe1yZxEIzIK"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(NREM_recunstruct):\n",
        "    NREM_recunstruct[i] = score + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU9WNF06IzIK"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHmit8iMIzIK"
      },
      "outputs": [],
      "source": [
        "def make_new_scoring(sleep_scoring, new_nrem, nrem_epochs):\n",
        "    sleep_array = np.array(sleep_scoring)\n",
        "    i = 0\n",
        "    for start, end in nrem_epochs:\n",
        "        segment_length = end - start\n",
        "        sleep_array[start:end] = new_nrem[i:i + segment_length]\n",
        "        i += segment_length\n",
        "    return sleep_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJUnWrd8IzIK"
      },
      "outputs": [],
      "source": [
        "final_scores = make_new_scoring(states_RGS14, NREM_recunstruct, nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3UQ1BJyIzIK"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(final_scores)):\n",
        "  if final_scores[i] == 3:\n",
        "    final_scores[i] = final_scores[i - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4sEoxF8IzIK"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(final_scores):\n",
        "  if score == 6:\n",
        "    final_scores[i] = 2\n",
        "  elif score == 7:\n",
        "    final_scores[i] = 3\n",
        "  elif score == 8:\n",
        "    final_scores[i] = 4\n",
        "  elif score == 4:\n",
        "    final_scores[i] = 5\n",
        "  elif score == 5:\n",
        "    final_scores[i] = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZSnnWSTIzIK"
      },
      "outputs": [],
      "source": [
        "score_labels = {1: 'Wake', 2:'N1', 3:'N2', 4:'N3', 5: 'Intermediate', 6: 'REM'}\n",
        "num_labels = {label: num for num, label in enumerate(score_labels.values(), start=1)}\n",
        "plt.figure(figsize=(16, 8))\n",
        "time_minutes = np.arange(0, len(final_scores)) / 60\n",
        "plt.step(time_minutes,final_scores)\n",
        "plt.title('Hypnogram of whole sleep - Upper 15th Percentile - RGS')\n",
        "plt.yticks(list(num_labels.values()), list(score_labels.values()))\n",
        "plt.xlabel(\"Time (minutes) - (10s window)\")\n",
        "plt.savefig('hypnogram_10s_15th.svg', format='svg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tatHbYAIzIK"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(final_scores, return_counts=True)\n",
        "percentages = counts / len(final_scores) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"Wake\", 'N1', 'N2', 'N3', 'Intermediate', 'REM'], color=['b', 'b', 'b', 'b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of sleep stages - Upper 15th Percentile (10s window) - RGS'\n",
        "plt.title(titlee)\n",
        "plt.savefig('Percentage-10s-15th.svg', format='svg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxoMMF8eIzIL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_nrem_epoch(filtered_signal, start_epoch, end_epoch, sleep_scoring, fs_signal=1000, fs_scoring=1):\n",
        "\n",
        "    start_idx_signal = start_epoch * fs_signal\n",
        "    end_idx_signal = end_epoch * fs_signal\n",
        "\n",
        "    nrem_signal_segment = filtered_signal[start_idx_signal:end_idx_signal]\n",
        "    nrem_scoring_segment = sleep_scoring[start_epoch:end_epoch]\n",
        "\n",
        "    total_batches = int(np.ceil(len(nrem_signal_segment) / (20 * fs_signal)))\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        batch_start_idx = i * 20 * fs_signal\n",
        "        batch_end_idx = min((i + 1) * 20 * fs_signal, len(nrem_signal_segment))\n",
        "\n",
        "        twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        twenty_sec_stages = nrem_scoring_segment[i * 20: (i + 1) * 20]\n",
        "\n",
        "        # Find indices for N1, N2, and N3 stages using np.where\n",
        "        n1_indices = np.where(twenty_sec_stages == 2)[0]\n",
        "        n2_indices = np.where(twenty_sec_stages == 3)[0]\n",
        "        n3_indices = np.where(twenty_sec_stages == 4)[0]\n",
        "\n",
        "        # Group consecutive indices into episodes\n",
        "        def find_episodes(indices):\n",
        "            episodes = []\n",
        "            if len(indices) > 0:\n",
        "                start = indices[0]\n",
        "                for j in range(1, len(indices)):\n",
        "                    if indices[j] != indices[j-1] + 1:\n",
        "                        episodes.append((start, indices[j-1]))\n",
        "                        start = indices[j]\n",
        "                episodes.append((start, indices[-1]))\n",
        "            return episodes\n",
        "\n",
        "        n1_episodes = find_episodes(n1_indices)\n",
        "        n2_episodes = find_episodes(n2_indices)\n",
        "        n3_episodes = find_episodes(n3_indices)\n",
        "\n",
        "        # Time axis for this batch\n",
        "        t = np.arange(batch_start_idx / fs_signal, batch_end_idx / fs_signal, 1 / fs_signal)\n",
        "\n",
        "        plt.figure(figsize=(16, 4.5))\n",
        "        plt.plot(t, twenty_sec_sig, color='gray', label='Signal')\n",
        "\n",
        "        for start_idx, end_idx in n1_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='green', label='N1' if start_idx == n1_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start_epoch}-{end_epoch} seconds, Batch {i+1}')\n",
        "\n",
        "        # Set y-axis limits\n",
        "        plt.ylim(-500, 500)\n",
        "\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skWV7rKCIzIL"
      },
      "outputs": [],
      "source": [
        "f_lowpass = 20\n",
        "band = (0.1, 4)\n",
        "n_cycles = 3\n",
        "low_sig = filter_signal_fir(pfc_data, fs, 'lowpass', f_lowpass, n_cycles=n_cycles, remove_edges=False)\n",
        "delta_signal = filter_signal_fir(low_sig, fs, 'bandpass', band, n_cycles=n_cycles, remove_edges=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPN6oTMufuy9"
      },
      "outputs": [],
      "source": [
        "def plot_nrem2(filtered_signal, raw_signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    # Segment the signals and scores\n",
        "    filtered_signal_segment = filtered_signal[start * fs: end * fs]\n",
        "    raw_signal_segment = raw_signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    # Calculate total number of batches\n",
        "    total_batches = int(np.ceil(len(filtered_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        # Determine batch start and end indices\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(filtered_signal_segment))\n",
        "\n",
        "        # Extract the signal and stages for the current batch\n",
        "        filtered_batch_sig = filtered_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        raw_batch_sig = raw_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        batch_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        # Extract N2 and N3 episodes\n",
        "        n2_episodes = extract_n2_episodes(batch_stages)\n",
        "        n3_episodes = extract_n3_episodes(batch_stages)\n",
        "\n",
        "        # Generate time array dynamically based on the actual length of the segment\n",
        "        t = np.arange(0, len(filtered_batch_sig) / fs, 1/fs)\n",
        "\n",
        "        plt.figure(figsize=(16, 9))\n",
        "\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(t, filtered_batch_sig, color='black', label='N1 (Filtered)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Filtered)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Filtered)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Filtered)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(t, raw_batch_sig, color='black', label='N1 (Raw)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Raw)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Raw)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)-10s-15th.svg', format='svg')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF3eb-Gak9Hy"
      },
      "outputs": [],
      "source": [
        "start, end = nrem_epochs[31]\n",
        "print('start: ', start, ' end: ', end)\n",
        "print((end - start + 1)/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBnQ67Mok9Hz"
      },
      "outputs": [],
      "source": [
        "plot_nrem2(delta_signal, pfc_data, final_scores, start, end, 30, fs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReS0EkCeAJRr"
      },
      "source": [
        "Tetxt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7442CFWjAHSf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcPvPWl-bptl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rvfN8zPbp5A"
      },
      "source": [
        "# CBD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO6-758zbp5D"
      },
      "outputs": [],
      "source": [
        "def find_all_NREM_epochs(arr):\n",
        "    nrem_epochs = []\n",
        "    start_index = None\n",
        "\n",
        "    for i, num in enumerate(arr):\n",
        "        if num == 3:\n",
        "            if start_index is None:\n",
        "                start_index = i\n",
        "        elif num != 3 and start_index is not None:\n",
        "            nrem_epochs.append([start_index, i - 1])\n",
        "            start_index = None\n",
        "\n",
        "    if start_index is not None:\n",
        "        nrem_epochs.append([start_index, len(arr) - 1])\n",
        "\n",
        "    return nrem_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uZbZvQ1bp5D"
      },
      "outputs": [],
      "source": [
        "def peak_before_trough(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 1, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return arr[i]\n",
        "  return -1\n",
        "\n",
        "def peak_before_trough_pos(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 1, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return i\n",
        "  return -1\n",
        "\n",
        "def peak_to_trough_duration(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 20, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return trough_pos-i\n",
        "  return -1\n",
        "\n",
        "def num_inflection_points(arr):\n",
        "  sign_changes = np.diff(np.sign(np.diff(arr, 2)))\n",
        "  num_inflection_points = np.sum(sign_changes != 0)\n",
        "  return num_inflection_points\n",
        "\n",
        "def compute_range(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "def asc2desc(x):\n",
        "    pt = emd.cycles.cf_peak_sample(x, interp=True)\n",
        "    tt = emd.cycles.cf_trough_sample(x, interp=True)\n",
        "    if (pt is None) or (tt is None):\n",
        "        return np.nan\n",
        "    asc = pt + (len(x) - tt)\n",
        "    desc = tt - pt\n",
        "    return asc / len(x)\n",
        "\n",
        "def peak2trough(x):\n",
        "    des = emd.cycles.cf_descending_zero_sample(x, interp=True)\n",
        "    if des is None:\n",
        "        return np.nan\n",
        "    return des / len(x)\n",
        "\n",
        "# Compute metrics for each cycle -\n",
        "def get_cycles_with_metrics(cycles, data, IA, IF, conditions=None):\n",
        "  C = copy.deepcopy(cycles)\n",
        "\n",
        "  C.compute_cycle_metric('duration_samples', data, func=len)\n",
        "  C.compute_cycle_metric('peak2trough', data, func=peak2trough)\n",
        "  C.compute_cycle_metric('asc2desc', data, func=asc2desc)\n",
        "  C.compute_cycle_metric('max_amp', IA, func=np.max)\n",
        "  C.compute_cycle_metric('trough_values', data, func=np.min)\n",
        "  C.compute_cycle_metric('peak_values', data, func=np.max)\n",
        "  C.compute_cycle_metric('mean_if', IF, func=np.mean)\n",
        "  C.compute_cycle_metric('max_if', IF, func=np.max)\n",
        "  C.compute_cycle_metric('range_if', IF, func=compute_range)\n",
        "\n",
        "  C.compute_cycle_metric('trough_position', data, func=np.argmin)\n",
        "  C.compute_cycle_metric('peak_position', data, func=np.argmax)\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FefMJBlXbp5D"
      },
      "outputs": [],
      "source": [
        "nrem_epochs = find_all_NREM_epochs(states_CBD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx91LdTPbp5D"
      },
      "outputs": [],
      "source": [
        "nrem_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qArlQyiRbp5D"
      },
      "outputs": [],
      "source": [
        "a = np.diff(nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQwPW1Hbbp5D"
      },
      "outputs": [],
      "source": [
        "b = a[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJrueIlAbp5D"
      },
      "outputs": [],
      "source": [
        "sum(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6UZbrCZbp5D"
      },
      "outputs": [],
      "source": [
        "# Joining all the NREM epochs and filtering the Delta band\n",
        "fs = 2500 # Sampling rate/frequency\n",
        "nrem_data = []\n",
        "for start, end in nrem_epochs:\n",
        "  pfc_data_part = lfp_CBD[start*fs:end*fs]\n",
        "  nrem_data.extend(pfc_data_part)\n",
        "nrem_data = np.array(nrem_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfc-Gx2Ubp5D"
      },
      "outputs": [],
      "source": [
        "# #nrem_filtered_data = filter_signal(nrem_data, fs, 'bandpass', (0.1, 4), n_cycles=3, filter_type='iir', butterworth_order=6, remove_edges=False)\n",
        "# cut_off = 20\n",
        "# low_sig = filter_signal_fir(nrem_data, fs, 'lowpass', cut_off, n_cycles=3, remove_edges=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nrem_filtered_data = filter_signal(nrem_data, fs, 'bandpass', (0.1, 4), n_cycles=3, filter_type='iir', butterworth_order=6, remove_edges=False)\n",
        "nrem_filtered_data = filter_signal_fir(nrem_data, fs,\n",
        "                                       'bandpass', (0.1, 4),\n",
        "                                       n_cycles=3, remove_edges=False,\n",
        "                                       print_transitions=True, plot_properties=True)\n",
        "# For testing, subset data\n",
        "# nrem_filtered_data = nrem_filtered_data[:fs*60*10]"
      ],
      "metadata": {
        "id": "o7DE8meNRSdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnQf2E67bp5D"
      },
      "outputs": [],
      "source": [
        "# Extract Instantaneous phase (IP), frequency and amplitude (from Hilbert Transform)\n",
        "IP, IF, IA = emd.spectra.frequency_transform(nrem_filtered_data, fs, 'hilbert')\n",
        "\n",
        "# Get cycles using IP\n",
        "C = emd.cycles.Cycles(IP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gnUMEe-bp5E"
      },
      "outputs": [],
      "source": [
        "cycles = get_cycles_with_metrics(C, nrem_filtered_data, IA, IF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a10uTHtzbp5E"
      },
      "outputs": [],
      "source": [
        "def get_cycles_with_conditions(cycles, fs, conditions):\n",
        "  C = copy.deepcopy(cycles)\n",
        "  metrics = C.get_metric_dataframe()\n",
        "\n",
        "  amp_thresh = np.percentile(IA, 25) # 25th percentile of the amplitude\n",
        "  peak_thresh = np.percentile(metrics['peak_values'], 85)\n",
        "  trough_thresh = np.percentile(metrics['trough_values'], 40)\n",
        "\n",
        "  lo_freq_duration = fs/0.1\n",
        "  hi_freq_duration = fs/4\n",
        "\n",
        "  C.pick_cycle_subset(conditions)\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PLxCxUKbp5E"
      },
      "outputs": [],
      "source": [
        "metrics = cycles.get_metric_dataframe()\n",
        "amp_thresh = np.percentile(IA, 25) # 25th percentile of the amplitude\n",
        "peak_thresh = np.percentile(metrics['peak_values'], 85)\n",
        "trough_thresh = np.percentile(metrics['trough_values'], 40)\n",
        "lo_freq_duration = fs/0.1\n",
        "hi_freq_duration = fs/4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1lr_2w3bp5E"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              # f'peak_values>={peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "all_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MW-TV2Ebp5E"
      },
      "outputs": [],
      "source": [
        "all_metrics = all_cycles.get_metric_dataframe(subset=True)\n",
        "all_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAkA2nB8bp5E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7jho_pubp5E"
      },
      "source": [
        "## Get SO and delta cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4MlaR8bbp5E"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              f'peak_values>={peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "so_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9KrFxqObp5E"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              f'peak_values<{peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "delta_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yXlF6o7bp5E"
      },
      "outputs": [],
      "source": [
        "metrics_so = so_cycles.get_metric_dataframe(subset=True)\n",
        "metrics_delta = delta_cycles.get_metric_dataframe(subset=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTJI_ZKubp5J"
      },
      "source": [
        "## Rate of SO and delta cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdPouQcrbp5J"
      },
      "outputs": [],
      "source": [
        "def get_masked_cycles(IP, cycles):\n",
        "  mask = np.full(cycles.nsamples, False)\n",
        "  subset_cycles = cycles.get_metric_dataframe(subset=True)['index']\n",
        "\n",
        "  for i in subset_cycles:\n",
        "    inds = cycles.get_inds_of_cycle(i)\n",
        "    mask[inds] = True\n",
        "\n",
        "  masked_so_cycles = emd.cycles.get_cycle_vector(IP, mask=mask)\n",
        "  return masked_so_cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4PQMVt7bp5K"
      },
      "outputs": [],
      "source": [
        "def rate_cycle(cycles_vector, duration=1, fs=1000):\n",
        "  samples_per_segment = duration * fs\n",
        "  segments = np.array_split(cycles_vector, np.arange(samples_per_segment, len(cycles_vector), samples_per_segment))\n",
        "  segments = np.array(segments[:-1])\n",
        "\n",
        "  rate = []\n",
        "  for segment in segments:\n",
        "    if -1 in segment:\n",
        "      rate.append(len(np.unique(segment))-1)\n",
        "    else:\n",
        "      rate.append(len(np.unique(segment)))\n",
        "  rate = np.array(rate)\n",
        "  rate = rate/duration\n",
        "  return rate, segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUIr1JNJbp5L"
      },
      "outputs": [],
      "source": [
        "so_cycles_vector = get_masked_cycles(IP, so_cycles)\n",
        "delta_cycles_vector = get_masked_cycles(IP, delta_cycles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEYIarKGbp5M"
      },
      "source": [
        "## 3s window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImhLx5cIbp5O"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate, _ = rate_cycle(so_cycles_vector, duration=3, fs=2500)\n",
        "delta_cycles_rate, _ = rate_cycle(delta_cycles_vector, duration=3, fs=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0OPmYfvbp5O"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.title('SO - Upper 15th Percentile - CBD')\n",
        "plt.bar(range(len(so_cycles_rate)), so_cycles_rate)\n",
        "plt.ylabel(\"Rate of SOs (Hz)\")\n",
        "plt.xlabel(\"Time (3 sec windows)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zel0frfJbp5P"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "plt.xlabel('Rates')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - window: 3s - Upper 15th Percentile')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W-yfrR2bp5P"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "\n",
        "min_x = min(so_cycles_rate)\n",
        "max_x = max(so_cycles_rate)\n",
        "x_ticks = np.arange(min_x, max_x + 0.1, 0.1)\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "plt.xlabel('Rates (window: 3s)')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - CBD')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwF8od9gbp5X"
      },
      "outputs": [],
      "source": [
        "def score_rates(so_cycles_rate):\n",
        "\n",
        "  score_array = np.zeros_like(so_cycles_rate)\n",
        "  for idx in range(len(so_cycles_rate)):\n",
        "    if so_cycles_rate[idx] < 0.2:\n",
        "      score_array[idx] = 1\n",
        "    elif so_cycles_rate[idx] <=0.8 and so_cycles_rate[idx]  >= 0.2:\n",
        "      score_array[idx] = 2\n",
        "    else:\n",
        "      score_array[idx] = 3\n",
        "  return score_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATHlahMMbp5Y"
      },
      "outputs": [],
      "source": [
        "score_array = score_rates(so_cycles_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erhb-iG2bp5Y"
      },
      "outputs": [],
      "source": [
        "np.unique(score_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYwittWHbp5f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score - Upper 15th Percentile - CBD')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time - window: 3s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN62nuw3bp5g"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(score_array, return_counts=True)\n",
        "percentages = counts / len(score_array) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"N1\", \"N2\", \"N3\"], color=['b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage (window: 3)')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of light and deep stages - Upper 15th Percentile - CBD'\n",
        "plt.title(titlee)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQy6crZ-bp5g"
      },
      "source": [
        "### Criterias for merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUCx8Ey-bp5n"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpsrBseibp5o"
      },
      "outputs": [],
      "source": [
        "NREM_recunstruct = []\n",
        "\n",
        "for score in score_array:\n",
        "  for _ in range(3):\n",
        "    NREM_recunstruct.append(score)\n",
        "NREM_recunstruct.append(score_array[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bibkiXEAbp5o"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBRAUvl1bp5r"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(NREM_recunstruct):\n",
        "    NREM_recunstruct[i] = score + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6Eb-3cFbp5s"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kct5RCmVbp5s"
      },
      "outputs": [],
      "source": [
        "def make_new_scoring(sleep_scoring, new_nrem, nrem_epochs):\n",
        "    sleep_array = np.array(sleep_scoring)\n",
        "    i = 0\n",
        "    for start, end in nrem_epochs:\n",
        "        segment_length = end - start\n",
        "        sleep_array[start:end] = new_nrem[i:i + segment_length]\n",
        "        i += segment_length\n",
        "    return sleep_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G_g_w9Cbp5v"
      },
      "outputs": [],
      "source": [
        "final_scores = make_new_scoring(states_CBD, NREM_recunstruct, nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Cr-UP9Wbp5w"
      },
      "outputs": [],
      "source": [
        "len(final_scores)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(states_CBD)"
      ],
      "metadata": {
        "id": "b7bvfaLQZA1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOlEC-cMbp5x"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(final_scores)):\n",
        "  if final_scores[i] == 3:\n",
        "    final_scores[i] = final_scores[i - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPkH0tE6bp5y"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(final_scores):\n",
        "  if score == 6:\n",
        "    final_scores[i] = 2\n",
        "  elif score == 7:\n",
        "    final_scores[i] = 3\n",
        "  elif score == 8:\n",
        "    final_scores[i] = 4\n",
        "  elif score == 4:\n",
        "    final_scores[i] = 5\n",
        "  elif score == 5:\n",
        "    final_scores[i] = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWXwADndbp5z"
      },
      "outputs": [],
      "source": [
        "score_labels = {1: 'Wake', 2:'N1', 3:'N2', 4:'N3', 5: 'Intermediate', 6: 'REM'}\n",
        "num_labels = {label: num for num, label in enumerate(score_labels.values(), start=1)}\n",
        "plt.figure(figsize=(16, 8))\n",
        "time_minutes = np.arange(0, len(final_scores)) / 60\n",
        "plt.step(time_minutes,final_scores)\n",
        "plt.title('Hypnogram of whole sleep - Upper 15th Percentile - CBD')\n",
        "plt.yticks(list(num_labels.values()), list(score_labels.values()))\n",
        "plt.xlabel(\"Time (minutes) - (3s window)\")\n",
        "plt.savefig('hypnogram_3s_15th.svg', format='svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "time_minutes = np.arange(0, len(states_CBD)) / 60\n",
        "plt.step(time_minutes,states_CBD)"
      ],
      "metadata": {
        "id": "tsWpSOEQKlOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2thc_bnbp50"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(final_scores, return_counts=True)\n",
        "percentages = counts / len(final_scores) * 100\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"Wake\", 'N1', 'N2', 'N3', 'Intermediate', 'REM'], color=['b', 'b', 'b', 'b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage (3s window)')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of sleep stages - Upper 15th Percentile - CBD'\n",
        "plt.title(titlee)\n",
        "plt.savefig('Percentage-3s-15th.svg', format='svg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9GDzYmhbp51"
      },
      "outputs": [],
      "source": [
        "f_lowpass = 20\n",
        "band = (0.1, 4)\n",
        "n_cycles = 3\n",
        "low_sig = filter_signal_fir(pfc_data, fs, 'lowpass', f_lowpass, n_cycles=n_cycles, remove_edges=False)\n",
        "delta_signal = filter_signal_fir(low_sig, fs, 'bandpass', band, n_cycles=n_cycles, remove_edges=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxx1kka1bp51"
      },
      "outputs": [],
      "source": [
        "np.unique(final_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiM-w3CMbp52"
      },
      "outputs": [],
      "source": [
        "def upscale_score(score_array, fs=1000):\n",
        "  scores = []\n",
        "  for i in range(len(score_array)):\n",
        "    for _ in range(fs):\n",
        "      scores.append(score_array[i])\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvlPMRaybp52"
      },
      "outputs": [],
      "source": [
        "def extract_n2_episodes(sleep_stages):\n",
        "    sleep_stages = np.asarray(sleep_stages).flatten()\n",
        "    n2_indices = np.where(sleep_stages == 3)[0]\n",
        "\n",
        "    episodes = []\n",
        "    if len(n2_indices) == 0:\n",
        "        return episodes\n",
        "\n",
        "    start_idx = None\n",
        "    for i in range(len(n2_indices)):\n",
        "        if start_idx is None:\n",
        "            start_idx = n2_indices[i]\n",
        "        if i == len(n2_indices) - 1 or n2_indices[i + 1] != n2_indices[i] + 1:\n",
        "            end_idx = n2_indices[i]\n",
        "            episodes.append((start_idx, end_idx))\n",
        "            start_idx = None\n",
        "\n",
        "    return episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ykn2FEB0bp52"
      },
      "outputs": [],
      "source": [
        "def extract_n3_episodes(sleep_stages):\n",
        "    sleep_stages = np.asarray(sleep_stages).flatten()\n",
        "    n3_indices = np.where(sleep_stages == 4)[0]\n",
        "\n",
        "    episodes = []\n",
        "    if len(n3_indices) == 0:\n",
        "        return episodes\n",
        "\n",
        "    start_idx = None\n",
        "    for i in range(len(n3_indices)):\n",
        "        if start_idx is None:\n",
        "            start_idx = n3_indices[i]\n",
        "        if i == len(n3_indices) - 1 or n3_indices[i + 1] != n3_indices[i] + 1:\n",
        "            end_idx = n3_indices[i]\n",
        "            episodes.append((start_idx, end_idx))\n",
        "            start_idx = None\n",
        "\n",
        "    return episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI4MafNNbp53"
      },
      "outputs": [],
      "source": [
        "nrem_signal_segment = delta_signal[start*fs: end*fs]\n",
        "score_segment = final_scores[start:end]\n",
        "upscaled_scores = upscale_score(score_segment, fs=1000)\n",
        "\n",
        "batch_length = 20\n",
        "\n",
        "total_batches = int(np.ceil(len(nrem_signal_segment) / (batch_length * fs)))\n",
        "print(start, ' ', end)\n",
        "print(total_batches)\n",
        "for i in range(total_batches):\n",
        "    batch_start_idx = i * batch_length * fs\n",
        "    batch_end_idx = min((i + 1) * batch_length * fs, len(nrem_signal_segment))\n",
        "\n",
        "    twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "    twenty_sec_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "    n2_episodes = extract_n2_episodes(twenty_sec_stages)\n",
        "    n3_episodes = extract_n3_episodes(twenty_sec_stages)\n",
        "\n",
        "    t = np.arange(0, len(twenty_sec_sig) / fs, 1/fs)\n",
        "\n",
        "    plt.figure(figsize=(16, 4.5))\n",
        "\n",
        "    plt.plot(t, twenty_sec_sig, color='black', label='N1')\n",
        "\n",
        "    for start_idx, end_idx in n2_episodes:\n",
        "        plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "    for start_idx, end_idx in n3_episodes:\n",
        "        plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.title('Filtered Signal with Sleep Stages Highlighted - filtered between 0.5 to 4Hz')\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    plt.legend(by_label.values(), by_label.keys())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYbIaBWObp56"
      },
      "outputs": [],
      "source": [
        "def plot_nrem(signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    nrem_signal_segment = signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    # Calculate total number of batches\n",
        "    total_batches = int(np.ceil(len(nrem_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        # Determine batch start and end indices\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(nrem_signal_segment))\n",
        "\n",
        "        # Extract the signal and stages for the current batch\n",
        "        twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        twenty_sec_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        # Extract N2 and N3 episodes\n",
        "        n2_episodes = extract_n2_episodes(twenty_sec_stages)\n",
        "        n3_episodes = extract_n3_episodes(twenty_sec_stages)\n",
        "        print(n2_episodes)\n",
        "        print(n3_episodes)\n",
        "        # Generate time array dynamically based on the actual length of the segment\n",
        "        t = np.arange(0, len(twenty_sec_sig) / fs, 1/fs)\n",
        "\n",
        "        plt.figure(figsize=(16, 4.5))\n",
        "        plt.plot(t, twenty_sec_sig, color='black', label='N1')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1}')\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxf09iuYbp57"
      },
      "outputs": [],
      "source": [
        "plot_nrem(delta_signal, final_scores, start, end, batch_length=20, fs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uQEh1jqbp57"
      },
      "outputs": [],
      "source": [
        "def plot_nrem2(filtered_signal, raw_signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    # Segment the signals and scores\n",
        "    filtered_signal_segment = filtered_signal[start * fs: end * fs]\n",
        "    raw_signal_segment = raw_signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    # Calculate total number of batches\n",
        "    total_batches = int(np.ceil(len(filtered_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        # Determine batch start and end indices\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(filtered_signal_segment))\n",
        "\n",
        "        # Extract the signal and stages for the current batch\n",
        "        filtered_batch_sig = filtered_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        raw_batch_sig = raw_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        batch_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        # Extract N2 and N3 episodes\n",
        "        n2_episodes = extract_n2_episodes(batch_stages)\n",
        "        n3_episodes = extract_n3_episodes(batch_stages)\n",
        "\n",
        "        # Generate time array dynamically based on the actual length of the segment\n",
        "        t = np.arange(0, len(filtered_batch_sig) / fs, 1/fs)\n",
        "\n",
        "        # Create the figure and the first subplot for the filtered signal\n",
        "        plt.figure(figsize=(16, 9))\n",
        "\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(t, filtered_batch_sig, color='black', label='N1 (Filtered)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Filtered)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Filtered)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Filtered)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(t, raw_batch_sig, color='black', label='N1 (Raw)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Raw)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Raw)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)-3s-15th.svg', format='svg')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6vlqfH0bp5-"
      },
      "outputs": [],
      "source": [
        "start, end = nrem_epochs[31]\n",
        "print(start, end)\n",
        "print((end - start + 1)/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX_vtjTMbp5-"
      },
      "outputs": [],
      "source": [
        "plot_nrem2(delta_signal, pfc_data, final_scores, start, end, 30, fs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPt22MkVbp5-"
      },
      "source": [
        "## 10s window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8i64ZGsbp5-"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate, _ = rate_cycle(so_cycles_vector, duration=10, fs=2500)\n",
        "delta_cycles_rate, _ = rate_cycle(delta_cycles_vector, duration=10, fs=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go7x3T8gbp5-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.title('SO - Upper 15th Percentile - CBD')\n",
        "plt.bar(range(len(so_cycles_rate)), so_cycles_rate)\n",
        "plt.xlabel(\"Time (10 sec windows)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x86302Mbp5_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "ax = sns.kdeplot(so_cycles_rate, fill=True)\n",
        "\n",
        "ax.set_xlabel('Rates')\n",
        "ax.set_ylabel('Density')\n",
        "\n",
        "ax.set_title('Distribution of Rates - window: 10s - upper 15th percentile')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6_q3qPEbp5_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "plt.xlabel('Rates')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - window: 3s')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sWP88AHbp5_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "\n",
        "min_x = min(so_cycles_rate)\n",
        "max_x = max(so_cycles_rate)\n",
        "x_ticks = np.arange(min_x, max_x + 0.1, 0.1)\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "plt.xlabel('Rates (window: 10s)')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - CBD')\n",
        "plt.savefig('histo_rates_10s_50th.svg', format='svg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJABmYtdbp6A"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUquqDKLbp6A"
      },
      "outputs": [],
      "source": [
        "def score_rates(so_cycles_rate):\n",
        "\n",
        "  score_array = np.zeros_like(so_cycles_rate)\n",
        "  for idx in range(len(so_cycles_rate)):\n",
        "    if so_cycles_rate[idx] < 0.2:\n",
        "      score_array[idx] = 1\n",
        "    elif so_cycles_rate[idx] <=0.6 and so_cycles_rate[idx]  >= 0.2:\n",
        "      score_array[idx] = 2\n",
        "    else:\n",
        "      score_array[idx] = 3\n",
        "  return score_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJqy9zdpbp6A"
      },
      "outputs": [],
      "source": [
        "score_array = score_rates(so_cycles_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBwHgFQCbp6B"
      },
      "outputs": [],
      "source": [
        "np.unique(score_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V18Vm8PAbp6C"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score - window: 10s')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32Hq6yIlbp6C"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(score_array, return_counts=True)\n",
        "percentages = counts / len(score_array) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"N1\", \"N2\", \"N3\"], color=['b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of light and deep stages - window: 10s - CBD'\n",
        "plt.title(titlee)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU3VKuPHbp6C"
      },
      "source": [
        "## Criterias for merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ah6MG_Xbp6C"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLCWvEdhbp6D"
      },
      "outputs": [],
      "source": [
        "NREM_recunstruct = []\n",
        "\n",
        "for score in score_array:\n",
        "  for _ in range(10):\n",
        "    NREM_recunstruct.append(score)\n",
        "for i in range(8):\n",
        "  NREM_recunstruct.append(score_array[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfWdvARdbp6D"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eHe5z1Wbp6D"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(NREM_recunstruct):\n",
        "    NREM_recunstruct[i] = score + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDYuZsQubp6D"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsywB7SYbp6D"
      },
      "outputs": [],
      "source": [
        "def make_new_scoring(sleep_scoring, new_nrem, nrem_epochs):\n",
        "    sleep_array = np.array(sleep_scoring)\n",
        "    i = 0\n",
        "    for start, end in nrem_epochs:\n",
        "        segment_length = end - start\n",
        "        sleep_array[start:end] = new_nrem[i:i + segment_length]\n",
        "        i += segment_length\n",
        "    return sleep_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRbeZmNsbp6D"
      },
      "outputs": [],
      "source": [
        "final_scores = make_new_scoring(states_CBD, NREM_recunstruct, nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ_dhUP_bp6D"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(final_scores)):\n",
        "  if final_scores[i] == 3:\n",
        "    final_scores[i] = final_scores[i - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwNrcKIMbp6D"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(final_scores):\n",
        "  if score == 6:\n",
        "    final_scores[i] = 2\n",
        "  elif score == 7:\n",
        "    final_scores[i] = 3\n",
        "  elif score == 8:\n",
        "    final_scores[i] = 4\n",
        "  elif score == 4:\n",
        "    final_scores[i] = 5\n",
        "  elif score == 5:\n",
        "    final_scores[i] = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s4BFHZabp6D"
      },
      "outputs": [],
      "source": [
        "score_labels = {1: 'Wake', 2:'N1', 3:'N2', 4:'N3', 5: 'Intermediate', 6: 'REM'}\n",
        "num_labels = {label: num for num, label in enumerate(score_labels.values(), start=1)}\n",
        "plt.figure(figsize=(16, 8))\n",
        "time_minutes = np.arange(0, len(final_scores)) / 60\n",
        "plt.step(time_minutes,final_scores)\n",
        "plt.title('Hypnogram of whole sleep - Upper 15th Percentile - CBD')\n",
        "plt.yticks(list(num_labels.values()), list(score_labels.values()))\n",
        "plt.xlabel(\"Time (minutes) - (10s window)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmOElRBHbp6D"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(final_scores, return_counts=True)\n",
        "percentages = counts / len(final_scores) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"Wake\", 'N1', 'N2', 'N3', 'Intermediate', 'REM'], color=['b', 'b', 'b', 'b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of sleep stages - Upper 15th Percentile (10s window) - CBD'\n",
        "plt.title(titlee)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVKH4EDubp6D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_nrem_epoch(filtered_signal, start_epoch, end_epoch, sleep_scoring, fs_signal=1000, fs_scoring=1):\n",
        "    # Calculate the corresponding indices in the signal\n",
        "    start_idx_signal = start_epoch * fs_signal\n",
        "    end_idx_signal = end_epoch * fs_signal\n",
        "\n",
        "    # Get the corresponding NREM signal segment and sleep scoring segment\n",
        "    nrem_signal_segment = filtered_signal[start_idx_signal:end_idx_signal]\n",
        "    nrem_scoring_segment = sleep_scoring[start_epoch:end_epoch]\n",
        "\n",
        "    # Calculate the total number of 20-second batches\n",
        "    total_batches = int(np.ceil(len(nrem_signal_segment) / (20 * fs_signal)))\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        batch_start_idx = i * 20 * fs_signal\n",
        "        batch_end_idx = min((i + 1) * 20 * fs_signal, len(nrem_signal_segment))\n",
        "\n",
        "        # Extract the 20-second batch for both signal and scoring\n",
        "        twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        twenty_sec_stages = nrem_scoring_segment[i * 20: (i + 1) * 20]\n",
        "\n",
        "        # Find indices for N1, N2, and N3 stages using np.where\n",
        "        n1_indices = np.where(twenty_sec_stages == 2)[0]\n",
        "        n2_indices = np.where(twenty_sec_stages == 3)[0]\n",
        "        n3_indices = np.where(twenty_sec_stages == 4)[0]\n",
        "\n",
        "        def find_episodes(indices):\n",
        "            episodes = []\n",
        "            if len(indices) > 0:\n",
        "                start = indices[0]\n",
        "                for j in range(1, len(indices)):\n",
        "                    if indices[j] != indices[j-1] + 1:\n",
        "                        episodes.append((start, indices[j-1]))\n",
        "                        start = indices[j]\n",
        "                episodes.append((start, indices[-1]))\n",
        "            return episodes\n",
        "\n",
        "        n1_episodes = find_episodes(n1_indices)\n",
        "        n2_episodes = find_episodes(n2_indices)\n",
        "        n3_episodes = find_episodes(n3_indices)\n",
        "\n",
        "        t = np.arange(batch_start_idx / fs_signal, batch_end_idx / fs_signal, 1 / fs_signal)\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(16, 4.5))\n",
        "        plt.plot(t, twenty_sec_sig, color='gray', label='Signal')\n",
        "\n",
        "        for start_idx, end_idx in n1_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='green', label='N1' if start_idx == n1_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start_epoch}-{end_epoch} seconds, Batch {i+1}')\n",
        "\n",
        "        # Set y-axis limits\n",
        "        plt.ylim(-500, 500)\n",
        "\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC2NDDhbbp6E"
      },
      "outputs": [],
      "source": [
        "f_lowpass = 20\n",
        "band = (0.1, 4)\n",
        "n_cycles = 3\n",
        "low_sig = filter_signal_fir(pfc_data, fs, 'lowpass', f_lowpass, n_cycles=n_cycles, remove_edges=False)\n",
        "delta_signal = filter_signal_fir(low_sig, fs, 'bandpass', band, n_cycles=n_cycles, remove_edges=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ElH9oiYbp6E"
      },
      "outputs": [],
      "source": [
        "def plot_nrem2(filtered_signal, raw_signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    # Segment the signals and scores\n",
        "    filtered_signal_segment = filtered_signal[start * fs: end * fs]\n",
        "    raw_signal_segment = raw_signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    # Calculate total number of batches\n",
        "    total_batches = int(np.ceil(len(filtered_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        # Determine batch start and end indices\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(filtered_signal_segment))\n",
        "\n",
        "        # Extract the signal and stages for the current batch\n",
        "        filtered_batch_sig = filtered_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        raw_batch_sig = raw_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        batch_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        # Extract N2 and N3 episodes\n",
        "        n2_episodes = extract_n2_episodes(batch_stages)\n",
        "        n3_episodes = extract_n3_episodes(batch_stages)\n",
        "\n",
        "        # Generate time array dynamically based on the actual length of the segment\n",
        "        t = np.arange(0, len(filtered_batch_sig) / fs, 1/fs)\n",
        "\n",
        "        # Create the figure and the first subplot for the filtered signal\n",
        "        plt.figure(figsize=(16, 9))\n",
        "\n",
        "        # Plot the filtered signal with sleep stages highlighted\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(t, filtered_batch_sig, color='black', label='N1 (Filtered)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Filtered)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Filtered)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Filtered)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        # Plot the raw signal in the second subplot\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(t, raw_batch_sig, color='black', label='N1 (Raw)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Raw)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Raw)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        # Adjust layout and show the plot\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)-10s-15th.svg', format='svg')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwyYU66Lbp6F"
      },
      "outputs": [],
      "source": [
        "start, end = nrem_epochs[31]\n",
        "print('start: ', start, ' end: ', end)\n",
        "print((end - start + 1)/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwO7u0h2bp6G"
      },
      "outputs": [],
      "source": [
        "plot_nrem2(delta_signal, pfc_data, final_scores, start, end, 30, fs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUk7aKUVbp6G"
      },
      "source": [
        "Tetxt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuF8Q_1abx7d"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERCK1wgIbzJG"
      },
      "source": [
        "# OS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4785aReCbzJI"
      },
      "outputs": [],
      "source": [
        "def find_all_NREM_epochs(arr):\n",
        "    nrem_epochs = []\n",
        "    start_index = None\n",
        "\n",
        "    for i, num in enumerate(arr):\n",
        "        if num == 3:\n",
        "            if start_index is None:\n",
        "                start_index = i\n",
        "        elif num != 3 and start_index is not None:\n",
        "            nrem_epochs.append([start_index, i - 1])\n",
        "            start_index = None\n",
        "\n",
        "    if start_index is not None:\n",
        "        nrem_epochs.append([start_index, len(arr) - 1])\n",
        "\n",
        "    return nrem_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0Bp_uaUbzJI"
      },
      "outputs": [],
      "source": [
        "def peak_before_trough(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 1, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return arr[i]\n",
        "  return -1\n",
        "\n",
        "def peak_before_trough_pos(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 1, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return i\n",
        "  return -1\n",
        "\n",
        "def peak_to_trough_duration(arr):\n",
        "  trough_val = np.min(arr)\n",
        "  trough_pos = np.argmin(arr)\n",
        "  for i in range(trough_pos - 20, 0, -1):\n",
        "    if arr[i] > arr[i - 1] and arr[i] > arr[i + 1] and arr[i]>=0:\n",
        "      return trough_pos-i\n",
        "  return -1\n",
        "\n",
        "def num_inflection_points(arr):\n",
        "  sign_changes = np.diff(np.sign(np.diff(arr, 2)))\n",
        "  num_inflection_points = np.sum(sign_changes != 0)\n",
        "  return num_inflection_points\n",
        "\n",
        "def compute_range(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "def asc2desc(x):\n",
        "    pt = emd.cycles.cf_peak_sample(x, interp=True)\n",
        "    tt = emd.cycles.cf_trough_sample(x, interp=True)\n",
        "    if (pt is None) or (tt is None):\n",
        "        return np.nan\n",
        "    asc = pt + (len(x) - tt)\n",
        "    desc = tt - pt\n",
        "    return asc / len(x)\n",
        "\n",
        "def peak2trough(x):\n",
        "    des = emd.cycles.cf_descending_zero_sample(x, interp=True)\n",
        "    if des is None:\n",
        "        return np.nan\n",
        "    return des / len(x)\n",
        "\n",
        "# Compute metrics for each cycle -\n",
        "def get_cycles_with_metrics(cycles, data, IA, IF, conditions=None):\n",
        "  C = copy.deepcopy(cycles)\n",
        "\n",
        "  C.compute_cycle_metric('duration_samples', data, func=len)\n",
        "  C.compute_cycle_metric('peak2trough', data, func=peak2trough)\n",
        "  C.compute_cycle_metric('asc2desc', data, func=asc2desc)\n",
        "  C.compute_cycle_metric('max_amp', IA, func=np.max)\n",
        "  C.compute_cycle_metric('trough_values', data, func=np.min)\n",
        "  C.compute_cycle_metric('peak_values', data, func=np.max)\n",
        "  C.compute_cycle_metric('mean_if', IF, func=np.mean)\n",
        "  C.compute_cycle_metric('max_if', IF, func=np.max)\n",
        "  C.compute_cycle_metric('range_if', IF, func=compute_range)\n",
        "\n",
        "  C.compute_cycle_metric('trough_position', data, func=np.argmin)\n",
        "  C.compute_cycle_metric('peak_position', data, func=np.argmax)\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlFAIMc_bzJJ"
      },
      "outputs": [],
      "source": [
        "nrem_epochs = find_all_NREM_epochs(states_OSB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeNFQBSHbzJJ"
      },
      "outputs": [],
      "source": [
        "nrem_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VnqlBiabzJJ"
      },
      "outputs": [],
      "source": [
        "a = np.diff(nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTPkKJXNbzJJ"
      },
      "outputs": [],
      "source": [
        "b = a[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGq5T3j-bzJK"
      },
      "outputs": [],
      "source": [
        "sum(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLCLOkfgbzJK"
      },
      "outputs": [],
      "source": [
        "# Joining all the NREM epochs and filtering the Delta band\n",
        "\n",
        "fs = 2500 # Sampling rate/frequency\n",
        "nrem_data_OSB = []\n",
        "for start, end in nrem_epochs:\n",
        "  pfc_data_part_OSB = lfp_OSB[start*fs:end*fs]\n",
        "  nrem_data_OSB.extend(pfc_data_part_OSB)\n",
        "nrem_data_OSB = np.array(nrem_data_OSB)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #nrem_filtered_data = filter_signal(nrem_data, fs, 'bandpass', (0.1, 4), n_cycles=3, filter_type='iir', butterworth_order=6, remove_edges=False)\n",
        "# cut_off = 20\n",
        "# low_sig = filter_signal_fir(nrem_data, fs, 'lowpass', cut_off, n_cycles=3, remove_edges=False)"
      ],
      "metadata": {
        "id": "ibO3tICXZpyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs"
      ],
      "metadata": {
        "id": "sWKiQvqIJr4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKn-eJ_sbzJK"
      },
      "outputs": [],
      "source": [
        "#nrem_filtered_data = filter_signal(nrem_data, fs, 'bandpass', (0.1, 4), n_cycles=3, filter_type='iir', butterworth_order=6, remove_edges=False)\n",
        "nrem_filtered_data = filter_signal_fir(nrem_data_OSB, fs,\n",
        "                                       'bandpass', (0.1, 4),\n",
        "                                       n_cycles=3, remove_edges=False)\n",
        "# For testing, subset data\n",
        "# nrem_filtered_data = nrem_filtered_data[:fs*60*10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHwByEKpbzJK"
      },
      "outputs": [],
      "source": [
        "# Extract Instantaneous phase (IP), frequency and amplitude (from Hilbert Transform)\n",
        "IP, IF, IA = emd.spectra.frequency_transform(nrem_filtered_data, fs, 'hilbert')\n",
        "\n",
        "# Get cycles using IP\n",
        "C = emd.cycles.Cycles(IP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vNQpzZqbzJK"
      },
      "outputs": [],
      "source": [
        "cycles = get_cycles_with_metrics(C, nrem_filtered_data, IA, IF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnS5t71sbzJK"
      },
      "outputs": [],
      "source": [
        "def get_cycles_with_conditions(cycles, fs, conditions):\n",
        "  C = copy.deepcopy(cycles)\n",
        "  metrics = C.get_metric_dataframe()\n",
        "\n",
        "  amp_thresh = np.percentile(IA, 25) # 25th percentile of the amplitude\n",
        "  peak_thresh = np.percentile(metrics['peak_values'], 85)\n",
        "  trough_thresh = np.percentile(metrics['trough_values'], 40)\n",
        "\n",
        "  lo_freq_duration = fs/0.1\n",
        "  hi_freq_duration = fs/4\n",
        "\n",
        "  C.pick_cycle_subset(conditions)\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQw2Dw1EbzJK"
      },
      "outputs": [],
      "source": [
        "metrics = cycles.get_metric_dataframe()\n",
        "amp_thresh = np.percentile(IA, 25) # 25th percentile of the amplitude\n",
        "peak_thresh = np.percentile(metrics['peak_values'], 85)\n",
        "trough_thresh = np.percentile(metrics['trough_values'], 40)\n",
        "lo_freq_duration = fs/0.1\n",
        "hi_freq_duration = fs/4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rip3dGpmbzJK"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              # f'peak_values>={peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "all_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcdGVt5sbzJK"
      },
      "outputs": [],
      "source": [
        "all_metrics = all_cycles.get_metric_dataframe(subset=True)\n",
        "all_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV_nMb3pbzJK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBxePOtabzJL"
      },
      "source": [
        "## Get SO and delta cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sDpj0QmbzJL"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              f'peak_values>={peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "so_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJP6IFA7bzJL"
      },
      "outputs": [],
      "source": [
        "conditions = ['is_good==1',\n",
        "              # f'max_amp>{amp_thresh}',\n",
        "              f'duration_samples<{lo_freq_duration}',\n",
        "              f'duration_samples>{hi_freq_duration}',\n",
        "              f'peak_values<{peak_thresh}',\n",
        "              f'trough_values<={trough_thresh}',\n",
        "              ]\n",
        "delta_cycles = get_cycles_with_conditions(cycles, fs, conditions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9B2OoDhbzJL"
      },
      "outputs": [],
      "source": [
        "metrics_so = so_cycles.get_metric_dataframe(subset=True)\n",
        "metrics_delta = delta_cycles.get_metric_dataframe(subset=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7nld1iPbzJL"
      },
      "source": [
        "## Rate of SO and delta cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbeGQxVbbzJL"
      },
      "outputs": [],
      "source": [
        "def get_masked_cycles(IP, cycles):\n",
        "  mask = np.full(cycles.nsamples, False)\n",
        "  subset_cycles = cycles.get_metric_dataframe(subset=True)['index']\n",
        "\n",
        "  for i in subset_cycles:\n",
        "    inds = cycles.get_inds_of_cycle(i)\n",
        "    mask[inds] = True\n",
        "\n",
        "  masked_so_cycles = emd.cycles.get_cycle_vector(IP, mask=mask)\n",
        "  return masked_so_cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu3Q58w1bzJL"
      },
      "outputs": [],
      "source": [
        "def rate_cycle(cycles_vector, duration=1, fs=1000):\n",
        "  samples_per_segment = duration * fs\n",
        "  segments = np.array_split(cycles_vector, np.arange(samples_per_segment, len(cycles_vector), samples_per_segment))\n",
        "  segments = np.array(segments[:-1])\n",
        "\n",
        "  rate = []\n",
        "  for segment in segments:\n",
        "    if -1 in segment:\n",
        "      rate.append(len(np.unique(segment))-1)\n",
        "    else:\n",
        "      rate.append(len(np.unique(segment)))\n",
        "  rate = np.array(rate)\n",
        "  rate = rate/duration\n",
        "  return rate, segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XByEbpjDbzJL"
      },
      "outputs": [],
      "source": [
        "so_cycles_vector = get_masked_cycles(IP, so_cycles)\n",
        "delta_cycles_vector = get_masked_cycles(IP, delta_cycles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPLwno_2bzJM"
      },
      "source": [
        "## 3s window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWotSStZbzJM"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate, _ = rate_cycle(so_cycles_vector, duration=3, fs=2500)\n",
        "delta_cycles_rate, _ = rate_cycle(delta_cycles_vector, duration=3, fs=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "424_AbYybzJM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.title('SO - Upper 15th Percentile - OS Basic')\n",
        "plt.bar(range(len(so_cycles_rate)), so_cycles_rate)\n",
        "plt.ylabel(\"Rate of SOs (Hz)\")\n",
        "plt.xlabel(\"Time (3 sec windows)\")\n",
        "plt.savefig('SO_rates_3s_15th.svg', format='svg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAzeb7jLbzJM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "plt.xlabel('Rates')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - window: 3s - Upper 15th Percentile')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaE2WWgKbzJN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "\n",
        "min_x = min(so_cycles_rate)\n",
        "max_x = max(so_cycles_rate)\n",
        "x_ticks = np.arange(min_x, max_x + 0.1, 0.1)\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "plt.xlabel('Rates (window: 3s)')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - OS Basic')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bgov3CWbzJN"
      },
      "outputs": [],
      "source": [
        "def score_rates(so_cycles_rate):\n",
        "\n",
        "  score_array = np.zeros_like(so_cycles_rate)\n",
        "  for idx in range(len(so_cycles_rate)):\n",
        "    if so_cycles_rate[idx] < 0.3:\n",
        "      score_array[idx] = 1\n",
        "    elif so_cycles_rate[idx] <=0.8 and so_cycles_rate[idx]  >= 0.3:\n",
        "      score_array[idx] = 2\n",
        "    else:\n",
        "      score_array[idx] = 3\n",
        "  return score_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dUcQoCmbzJN"
      },
      "outputs": [],
      "source": [
        "score_array = score_rates(so_cycles_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC8GK0ecbzJN"
      },
      "outputs": [],
      "source": [
        "np.unique(score_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWF5MvzAbzJN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score - Upper 15th Percentile - OS Basic')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time - window: 3s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63W8Y6otbzJO"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(score_array, return_counts=True)\n",
        "percentages = counts / len(score_array) * 100\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"N1\", \"N2\", \"N3\"], color=['b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage (window: 3)')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of light and deep stages - Upper 15th Percentile - OS Basic'\n",
        "plt.title(titlee)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEsoHXfDbzJO"
      },
      "source": [
        "### Criterias for merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOQpX2w_bzJO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q79cO2KbzJO"
      },
      "outputs": [],
      "source": [
        "NREM_recunstruct = []\n",
        "\n",
        "for score in score_array:\n",
        "  for _ in range(3):\n",
        "    NREM_recunstruct.append(score)\n",
        "NREM_recunstruct.append(score_array[-1])\n",
        "NREM_recunstruct.append(score_array[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwEpIUNWbzJO"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKQbfGvHbzJP"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(NREM_recunstruct):\n",
        "    NREM_recunstruct[i] = score + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2Inldq4bzJQ"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Jidx2pbzJQ"
      },
      "outputs": [],
      "source": [
        "def make_new_scoring(sleep_scoring, new_nrem, nrem_epochs):\n",
        "    sleep_array = np.array(sleep_scoring)\n",
        "    i = 0\n",
        "    for start, end in nrem_epochs:\n",
        "        segment_length = end - start\n",
        "        sleep_array[start:end] = new_nrem[i:i + segment_length]\n",
        "        i += segment_length\n",
        "    return sleep_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0G37-ETbzJQ"
      },
      "outputs": [],
      "source": [
        "final_scores = make_new_scoring(states_OSB, NREM_recunstruct, nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cweDdoFbzJQ"
      },
      "outputs": [],
      "source": [
        "len(final_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPuAIXvnbzJQ"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(final_scores)):\n",
        "  if final_scores[i] == 3:\n",
        "    final_scores[i] = final_scores[i - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nakUOxrXbzJQ"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(final_scores):\n",
        "  if score == 6:\n",
        "    final_scores[i] = 2\n",
        "  elif score == 7:\n",
        "    final_scores[i] = 3\n",
        "  elif score == 8:\n",
        "    final_scores[i] = 4\n",
        "  elif score == 4:\n",
        "    final_scores[i] = 5\n",
        "  elif score == 5:\n",
        "    final_scores[i] = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ie-v0oHbzJQ"
      },
      "outputs": [],
      "source": [
        "score_labels = {1: 'Wake', 2:'N1', 3:'N2', 4:'N3', 5: 'Intermediate', 6: 'REM'}\n",
        "num_labels = {label: num for num, label in enumerate(score_labels.values(), start=1)}\n",
        "plt.figure(figsize=(16, 8))\n",
        "time_minutes = np.arange(0, len(final_scores)) / 60\n",
        "plt.step(time_minutes,final_scores)\n",
        "plt.title('Hypnogram of whole sleep - Upper 15th Percentile - OS Basic')\n",
        "plt.yticks(list(num_labels.values()), list(score_labels.values()))\n",
        "plt.xlabel(\"Time (minutes) - (3s window)\")\n",
        "plt.savefig('hypnogram_3s_15th.svg', format='svg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hrrAry6bzJQ"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(final_scores, return_counts=True)\n",
        "percentages = counts / len(final_scores) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"Wake\", 'N1', 'N2', 'N3', 'Intermediate', 'REM'], color=['b', 'b', 'b', 'b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage (3s window)')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of sleep stages - Upper 15th Percentile - OS Basic'\n",
        "plt.title(titlee)\n",
        "plt.savefig('Percentage-3s-15th.svg', format='svg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MHb-HazbzJR"
      },
      "outputs": [],
      "source": [
        "f_lowpass = 20\n",
        "band = (0.1, 4)\n",
        "n_cycles = 3\n",
        "low_sig = filter_signal_fir(pfc_data, fs, 'lowpass', f_lowpass, n_cycles=n_cycles, remove_edges=False)\n",
        "delta_signal = filter_signal_fir(low_sig, fs, 'bandpass', band, n_cycles=n_cycles, remove_edges=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDjqdImebzJR"
      },
      "outputs": [],
      "source": [
        "np.unique(final_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD2cejHLbzJR"
      },
      "outputs": [],
      "source": [
        "def upscale_score(score_array, fs=1000):\n",
        "  scores = []\n",
        "  for i in range(len(score_array)):\n",
        "    for _ in range(fs):\n",
        "      scores.append(score_array[i])\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hC2lTBpbzJR"
      },
      "outputs": [],
      "source": [
        "def extract_n2_episodes(sleep_stages):\n",
        "    sleep_stages = np.asarray(sleep_stages).flatten()\n",
        "    n2_indices = np.where(sleep_stages == 3)[0]\n",
        "\n",
        "    episodes = []\n",
        "    if len(n2_indices) == 0:\n",
        "        return episodes\n",
        "\n",
        "    start_idx = None\n",
        "    for i in range(len(n2_indices)):\n",
        "        if start_idx is None:\n",
        "            start_idx = n2_indices[i]\n",
        "        if i == len(n2_indices) - 1 or n2_indices[i + 1] != n2_indices[i] + 1:\n",
        "            end_idx = n2_indices[i]\n",
        "            episodes.append((start_idx, end_idx))\n",
        "            start_idx = None\n",
        "\n",
        "    return episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pmD2WUabzJR"
      },
      "outputs": [],
      "source": [
        "def extract_n3_episodes(sleep_stages):\n",
        "    sleep_stages = np.asarray(sleep_stages).flatten()\n",
        "    n3_indices = np.where(sleep_stages == 4)[0]\n",
        "\n",
        "    episodes = []\n",
        "    if len(n3_indices) == 0:\n",
        "        return episodes\n",
        "\n",
        "    start_idx = None\n",
        "    for i in range(len(n3_indices)):\n",
        "        if start_idx is None:\n",
        "            start_idx = n3_indices[i]\n",
        "        if i == len(n3_indices) - 1 or n3_indices[i + 1] != n3_indices[i] + 1:\n",
        "            end_idx = n3_indices[i]\n",
        "            episodes.append((start_idx, end_idx))\n",
        "            start_idx = None\n",
        "\n",
        "    return episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M59Y2okdbzJR"
      },
      "outputs": [],
      "source": [
        "nrem_signal_segment = delta_signal[start*fs: end*fs]\n",
        "score_segment = final_scores[start:end]\n",
        "upscaled_scores = upscale_score(score_segment, fs=1000)\n",
        "\n",
        "batch_length = 20\n",
        "\n",
        "total_batches = int(np.ceil(len(nrem_signal_segment) / (batch_length * fs)))\n",
        "print(start, ' ', end)\n",
        "print(total_batches)\n",
        "for i in range(total_batches):\n",
        "    batch_start_idx = i * batch_length * fs\n",
        "    batch_end_idx = min((i + 1) * batch_length * fs, len(nrem_signal_segment))\n",
        "\n",
        "    twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "    twenty_sec_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "    n2_episodes = extract_n2_episodes(twenty_sec_stages)\n",
        "    n3_episodes = extract_n3_episodes(twenty_sec_stages)\n",
        "\n",
        "    t = np.arange(0, len(twenty_sec_sig) / fs, 1/fs)\n",
        "\n",
        "    plt.figure(figsize=(16, 4.5))\n",
        "\n",
        "    plt.plot(t, twenty_sec_sig, color='black', label='N1')\n",
        "\n",
        "    for start_idx, end_idx in n2_episodes:\n",
        "        plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "    for start_idx, end_idx in n3_episodes:\n",
        "        plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.title('Filtered Signal with Sleep Stages Highlighted - filtered between 0.5 to 4Hz')\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    plt.legend(by_label.values(), by_label.keys())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUzk9gxbbzJS"
      },
      "outputs": [],
      "source": [
        "def plot_nrem(signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    nrem_signal_segment = signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    # Calculate total number of batches\n",
        "    total_batches = int(np.ceil(len(nrem_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        # Determine batch start and end indices\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(nrem_signal_segment))\n",
        "\n",
        "        # Extract the signal and stages for the current batch\n",
        "        twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        twenty_sec_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        # Extract N2 and N3 episodes\n",
        "        n2_episodes = extract_n2_episodes(twenty_sec_stages)\n",
        "        n3_episodes = extract_n3_episodes(twenty_sec_stages)\n",
        "        print(n2_episodes)\n",
        "        print(n3_episodes)\n",
        "        # Generate time array dynamically based on the actual length of the segment\n",
        "        t = np.arange(0, len(twenty_sec_sig) / fs, 1/fs)\n",
        "\n",
        "        # Plot the signal with sleep stages highlighted\n",
        "        plt.figure(figsize=(16, 4.5))\n",
        "        plt.plot(t, twenty_sec_sig, color='black', label='N1')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1}')\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH5e5TTBbzJS"
      },
      "outputs": [],
      "source": [
        "plot_nrem(delta_signal, final_scores, start, end, batch_length=20, fs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3LwEw3zbzJS"
      },
      "outputs": [],
      "source": [
        "def plot_nrem2(filtered_signal, raw_signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    # Segment the signals and scores\n",
        "    filtered_signal_segment = filtered_signal[start * fs: end * fs]\n",
        "    raw_signal_segment = raw_signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    # Calculate total number of batches\n",
        "    total_batches = int(np.ceil(len(filtered_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        # Determine batch start and end indices\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(filtered_signal_segment))\n",
        "\n",
        "        # Extract the signal and stages for the current batch\n",
        "        filtered_batch_sig = filtered_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        raw_batch_sig = raw_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        batch_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        # Extract N2 and N3 episodes\n",
        "        n2_episodes = extract_n2_episodes(batch_stages)\n",
        "        n3_episodes = extract_n3_episodes(batch_stages)\n",
        "\n",
        "        # Generate time array dynamically based on the actual length of the segment\n",
        "        t = np.arange(0, len(filtered_batch_sig) / fs, 1/fs)\n",
        "\n",
        "        # Create the figure and the first subplot for the filtered signal\n",
        "        plt.figure(figsize=(16, 9))\n",
        "\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(t, filtered_batch_sig, color='black', label='N1 (Filtered)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Filtered)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Filtered)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Filtered)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(t, raw_batch_sig, color='black', label='N1 (Raw)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Raw)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Raw)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)-3s-15th.svg', format='svg')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lS-h5AQbzJS"
      },
      "outputs": [],
      "source": [
        "start, end = nrem_epochs[31]\n",
        "print(start, end)\n",
        "print((end - start + 1)/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrGR2GRqbzJT"
      },
      "outputs": [],
      "source": [
        "plot_nrem2(delta_signal, pfc_data, final_scores, start, end, 30, fs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC0J4N8kbzJT"
      },
      "source": [
        "## 10s window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yRUx1R-bzJT"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate, _ = rate_cycle(so_cycles_vector, duration=10, fs=2500)\n",
        "delta_cycles_rate, _ = rate_cycle(delta_cycles_vector, duration=10, fs=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENVQfdE1bzJT"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.title('SO - Upper 15th Percentile - OS Basic')\n",
        "plt.bar(range(len(so_cycles_rate)), so_cycles_rate)\n",
        "plt.ylabel(\"Rate of SOs (Hz)\")\n",
        "plt.xlabel(\"Time (10 sec windows)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaIwwbgmbzJT"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "ax = sns.kdeplot(so_cycles_rate, fill=True)\n",
        "\n",
        "ax.set_xlabel('Rates')\n",
        "ax.set_ylabel('Density')\n",
        "\n",
        "ax.set_title('Distribution of Rates - window: 10s - upper 15th percentile')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSlzrKYHbzJT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "plt.xlabel('Rates')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - window: 3s')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3KWX7R9bzJT"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "weights = [100 / len(so_cycles_rate)] * len(so_cycles_rate)\n",
        "\n",
        "plt.hist(so_cycles_rate, bins=30, weights=weights)\n",
        "\n",
        "min_x = min(so_cycles_rate)\n",
        "max_x = max(so_cycles_rate)\n",
        "x_ticks = np.arange(min_x, max_x + 0.1, 0.1)\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "plt.xlabel('Rates (window: 10s)')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Histogram of Rates - OS Basic')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7iFZFlobzJU"
      },
      "outputs": [],
      "source": [
        "so_cycles_rate.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AApAUwNWbzJU"
      },
      "outputs": [],
      "source": [
        "def score_rates(so_cycles_rate):\n",
        "\n",
        "  score_array = np.zeros_like(so_cycles_rate)\n",
        "  for idx in range(len(so_cycles_rate)):\n",
        "    if so_cycles_rate[idx] < 0.3:\n",
        "      score_array[idx] = 1\n",
        "    elif so_cycles_rate[idx] <=0.8 and so_cycles_rate[idx]  >= 0.3:\n",
        "      score_array[idx] = 2\n",
        "    else:\n",
        "      score_array[idx] = 3\n",
        "  return score_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78gDdSCEbzJU"
      },
      "outputs": [],
      "source": [
        "score_array = score_rates(so_cycles_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDfy1X3BbzJU"
      },
      "outputs": [],
      "source": [
        "np.unique(score_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3YlL-M3bzJU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score - window: 10s')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MHB33OgbzJU"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(score_array, return_counts=True)\n",
        "percentages = counts / len(score_array) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"N1\", \"N2\", \"N3\"], color=['b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of light and deep stages - window: 10s - OS Basic'\n",
        "plt.title(titlee)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffghD8XabzJU"
      },
      "source": [
        "## Criterias for merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65pF8Om2bzJU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "time = np.arange(0, len(score_array))\n",
        "plt.step(time, score_array)\n",
        "plt.title('SO Score')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mgoecFdbzJU"
      },
      "outputs": [],
      "source": [
        "NREM_recunstruct = []\n",
        "\n",
        "for score in score_array:\n",
        "  for _ in range(10):\n",
        "    NREM_recunstruct.append(score)\n",
        "for i in range(8):\n",
        "  NREM_recunstruct.append(score_array[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBxv2WGNbzJV"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQQUzsSfbzJV"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(NREM_recunstruct):\n",
        "    NREM_recunstruct[i] = score + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3Beq2j9bzJV"
      },
      "outputs": [],
      "source": [
        "len(NREM_recunstruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRkr9p9WbzJV"
      },
      "outputs": [],
      "source": [
        "def make_new_scoring(sleep_scoring, new_nrem, nrem_epochs):\n",
        "    sleep_array = np.array(sleep_scoring)\n",
        "    i = 0\n",
        "    for start, end in nrem_epochs:\n",
        "        segment_length = end - start\n",
        "        sleep_array[start:end] = new_nrem[i:i + segment_length]\n",
        "        i += segment_length\n",
        "    return sleep_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIQNq-TvbzJV"
      },
      "outputs": [],
      "source": [
        "final_scores = make_new_scoring(states_OSB, NREM_recunstruct, nrem_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agY4ulstbzJV"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(final_scores)):\n",
        "  if final_scores[i] == 3:\n",
        "    final_scores[i] = final_scores[i - 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgUPUieQbzJW"
      },
      "outputs": [],
      "source": [
        "for i, score in enumerate(final_scores):\n",
        "  if score == 6:\n",
        "    final_scores[i] = 2\n",
        "  elif score == 7:\n",
        "    final_scores[i] = 3\n",
        "  elif score == 8:\n",
        "    final_scores[i] = 4\n",
        "  elif score == 4:\n",
        "    final_scores[i] = 5\n",
        "  elif score == 5:\n",
        "    final_scores[i] = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNBkJsVFbzJW"
      },
      "outputs": [],
      "source": [
        "score_labels = {1: 'Wake', 2:'N1', 3:'N2', 4:'N3', 5: 'Intermediate', 6: 'REM'}\n",
        "num_labels = {label: num for num, label in enumerate(score_labels.values(), start=1)}\n",
        "plt.figure(figsize=(16, 8))\n",
        "time_minutes = np.arange(0, len(final_scores)) / 60\n",
        "plt.step(time_minutes,final_scores)\n",
        "plt.title('Hypnogram of whole sleep - Upper 15th Percentile - OS Basic')\n",
        "plt.yticks(list(num_labels.values()), list(score_labels.values()))\n",
        "plt.xlabel(\"Time (minutes) - (10s window)\")\n",
        "plt.savefig('hypnogram_10s_15th.svg', format='svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(final_scores, return_counts=True)"
      ],
      "metadata": {
        "id": "5sYuyk4lWZWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique"
      ],
      "metadata": {
        "id": "CeQIgWERWaAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgWYre6VbzJW"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(final_scores, return_counts=True)\n",
        "percentages = counts / len(final_scores) * 100\n",
        "\n",
        "# Create a bar chart for the percentages\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(unique, percentages, tick_label=[\"Wake\", 'N1', 'N2', 'N3', 'Intermediate', 'REM'], color=['b', 'b', 'b', 'b', 'b', 'b'])\n",
        "plt.xlabel('Sleep Stage')\n",
        "plt.ylabel('Percentage')\n",
        "titlee = 'Percentage of sleep stages - Upper 15th Percentile (10s window) - OS Basic'\n",
        "plt.title(titlee)\n",
        "plt.savefig('Percentage-10s-15th.svg', format='svg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQz4bLb1bzJW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_nrem_epoch(filtered_signal, start_epoch, end_epoch, sleep_scoring, fs_signal=1000, fs_scoring=1):\n",
        "    # Calculate the corresponding indices in the signal\n",
        "    start_idx_signal = start_epoch * fs_signal\n",
        "    end_idx_signal = end_epoch * fs_signal\n",
        "\n",
        "    # Get the corresponding NREM signal segment and sleep scoring segment\n",
        "    nrem_signal_segment = filtered_signal[start_idx_signal:end_idx_signal]\n",
        "    nrem_scoring_segment = sleep_scoring[start_epoch:end_epoch]\n",
        "\n",
        "    # Calculate the total number of 20-second batches\n",
        "    total_batches = int(np.ceil(len(nrem_signal_segment) / (20 * fs_signal)))\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        batch_start_idx = i * 20 * fs_signal\n",
        "        batch_end_idx = min((i + 1) * 20 * fs_signal, len(nrem_signal_segment))\n",
        "\n",
        "        # Extract the 20-second batch for both signal and scoring\n",
        "        twenty_sec_sig = nrem_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        twenty_sec_stages = nrem_scoring_segment[i * 20: (i + 1) * 20]\n",
        "\n",
        "        # Find indices for N1, N2, and N3 stages using np.where\n",
        "        n1_indices = np.where(twenty_sec_stages == 2)[0]\n",
        "        n2_indices = np.where(twenty_sec_stages == 3)[0]\n",
        "        n3_indices = np.where(twenty_sec_stages == 4)[0]\n",
        "\n",
        "        # Group consecutive indices into episodes\n",
        "        def find_episodes(indices):\n",
        "            episodes = []\n",
        "            if len(indices) > 0:\n",
        "                start = indices[0]\n",
        "                for j in range(1, len(indices)):\n",
        "                    if indices[j] != indices[j-1] + 1:\n",
        "                        episodes.append((start, indices[j-1]))\n",
        "                        start = indices[j]\n",
        "                episodes.append((start, indices[-1]))\n",
        "            return episodes\n",
        "\n",
        "        n1_episodes = find_episodes(n1_indices)\n",
        "        n2_episodes = find_episodes(n2_indices)\n",
        "        n3_episodes = find_episodes(n3_indices)\n",
        "\n",
        "        # Time axis for this batch\n",
        "        t = np.arange(batch_start_idx / fs_signal, batch_end_idx / fs_signal, 1 / fs_signal)\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(16, 4.5))\n",
        "        plt.plot(t, twenty_sec_sig, color='gray', label='Signal')\n",
        "\n",
        "        for start_idx, end_idx in n1_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='green', label='N1' if start_idx == n1_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='red', label='N2' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], twenty_sec_sig[start_idx:end_idx + 1], color='blue', label='N3' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start_epoch}-{end_epoch} seconds, Batch {i+1}')\n",
        "\n",
        "        # Set y-axis limits\n",
        "        plt.ylim(-500, 500)\n",
        "\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-doV4GH-bzJX"
      },
      "outputs": [],
      "source": [
        "f_lowpass = 20\n",
        "band = (0.1, 4)\n",
        "n_cycles = 3\n",
        "low_sig = filter_signal_fir(pfc_data, fs, 'lowpass', f_lowpass, n_cycles=n_cycles, remove_edges=False)\n",
        "delta_signal = filter_signal_fir(low_sig, fs, 'bandpass', band, n_cycles=n_cycles, remove_edges=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQBsD6RrbzJX"
      },
      "outputs": [],
      "source": [
        "def plot_nrem2(filtered_signal, raw_signal, scores, start, end, batch_length, fs=1000):\n",
        "\n",
        "    # Segment the signals and scores\n",
        "    filtered_signal_segment = filtered_signal[start * fs: end * fs]\n",
        "    raw_signal_segment = raw_signal[start * fs: end * fs]\n",
        "    score_segment = scores[start:end]\n",
        "    upscaled_scores = upscale_score(score_segment, fs=fs)\n",
        "\n",
        "    # Calculate total number of batches\n",
        "    total_batches = int(np.ceil(len(filtered_signal_segment) / (batch_length * fs)))\n",
        "    print(f\"Start: {start}, End: {end}\")\n",
        "    print(f\"Total Batches: {total_batches}\")\n",
        "\n",
        "    for i in range(total_batches):\n",
        "        # Determine batch start and end indices\n",
        "        batch_start_idx = i * batch_length * fs\n",
        "        batch_end_idx = min((i + 1) * batch_length * fs, len(filtered_signal_segment))\n",
        "\n",
        "        # Extract the signal and stages for the current batch\n",
        "        filtered_batch_sig = filtered_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        raw_batch_sig = raw_signal_segment[batch_start_idx:batch_end_idx]\n",
        "        batch_stages = upscaled_scores[batch_start_idx:batch_end_idx]\n",
        "\n",
        "        # Extract N2 and N3 episodes\n",
        "        n2_episodes = extract_n2_episodes(batch_stages)\n",
        "        n3_episodes = extract_n3_episodes(batch_stages)\n",
        "\n",
        "        # Generate time array dynamically based on the actual length of the segment\n",
        "        t = np.arange(0, len(filtered_batch_sig) / fs, 1/fs)\n",
        "\n",
        "        # Create the figure and the first subplot for the filtered signal\n",
        "        plt.figure(figsize=(16, 9))\n",
        "\n",
        "        # Plot the filtered signal with sleep stages highlighted\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(t, filtered_batch_sig, color='black', label='N1 (Filtered)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Filtered)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], filtered_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Filtered)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Filtered)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        # Plot the raw signal in the second subplot\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(t, raw_batch_sig, color='black', label='N1 (Raw)')\n",
        "\n",
        "        for start_idx, end_idx in n2_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='red', label='N2 (Raw)' if start_idx == n2_episodes[0][0] else \"\")\n",
        "\n",
        "        for start_idx, end_idx in n3_episodes:\n",
        "            plt.plot(t[start_idx:end_idx + 1], raw_batch_sig[start_idx:end_idx + 1], color='blue', label='N3 (Raw)' if start_idx == n3_episodes[0][0] else \"\")\n",
        "\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.title(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)')\n",
        "        plt.ylim(-600, 600)\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        by_label = dict(zip(labels, handles))\n",
        "        plt.legend(by_label.values(), by_label.keys())\n",
        "\n",
        "        # Adjust layout and show the plot\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'NREM Epoch: {start}-{end} seconds, Batch {i+1} (Raw)-10s-15th.svg', format='svg')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KmGVQ3YbzJX"
      },
      "outputs": [],
      "source": [
        "start, end = nrem_epochs[31]\n",
        "print('start: ', start, ' end: ', end)\n",
        "print((end - start + 1)/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omPugbKpbzJX"
      },
      "outputs": [],
      "source": [
        "plot_nrem2(delta_signal, pfc_data, final_scores, start, end, 30, fs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHxTfR1dbzJX"
      },
      "source": [
        "Tetxt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjQm5JVmbzJX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYqfAOvVbzJX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}